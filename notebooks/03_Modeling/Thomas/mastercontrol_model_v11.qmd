---
title: "MasterControl — Lead Scoring & Conversion Optimization"
author: "Thomas Beck · Max Ridgeway · Astha KC"
date: "Spring 2026"
format:
  html:
    embed-resources: true
    theme: flatly
    highlight-style: tango
    toc: true
    toc-depth: 3
    toc-location: left
    number-sections: false
    df-print: paged
    code-fold: show
    code-tools: true
execute:
  echo: false
  warning: false
  message: false
  fig-width: 10
  fig-height: 6
  fig-dpi: 150
  out-width: "100%"
editor_options:
  chunk_output_type: inline
---

```{python}
#| label: setup
#| include: false

# -----------------------------------------------------------------------------
# Setup and global configuration
# -----------------------------------------------------------------------------
import subprocess
import sys
import warnings
import time
import re
import multiprocessing
import numpy as np
import pandas as pd

warnings.filterwarnings('ignore')
np.random.seed(42)

START_TIME = time.time()
```

```{python}
#| label: dependencies
#| include: false

# -----------------------------------------------------------------------------
# Dependency management
# -----------------------------------------------------------------------------
def install_if_missing(package_name, import_name=None, pip_name=None):
    """Install a package if not already available."""
    import_name = import_name or package_name.lower()
    pip_name = pip_name or import_name
    try:
        __import__(import_name)
    except ImportError:
        subprocess.check_call(
            [sys.executable, "-m", "pip", "install", pip_name, "-q"],
            stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL
        )

for pkg in [("scikit-learn", "sklearn", "scikit-learn"), ("pyprojroot", None, None),
            ("CatBoost", "catboost", None), ("XGBoost", "xgboost", None),
            ("LightGBM", "lightgbm", None), ("SHAP", "shap", None),
            ("matplotlib", None, None), ("seaborn", None, None),
            ("tabulate", None, None)]:
    install_if_missing(*pkg)
```

```{python}
#| label: imports
#| include: false

# -----------------------------------------------------------------------------
# Core imports
# -----------------------------------------------------------------------------
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from pyprojroot import here
from types import SimpleNamespace
from tabulate import tabulate

# ML imports
from sklearn.model_selection import (
    train_test_split, StratifiedKFold, RandomizedSearchCV, cross_val_predict
)
from sklearn.preprocessing import StandardScaler, LabelEncoder, FunctionTransformer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import TruncatedSVD
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin, clone
from sklearn.metrics import (
    roc_auc_score, roc_curve, precision_recall_curve, average_precision_score,
    classification_report, confusion_matrix, brier_score_loss, log_loss,
    f1_score, precision_score, recall_score
)
from sklearn.calibration import CalibratedClassifierCV, calibration_curve
from sklearn.ensemble import (
    RandomForestClassifier, GradientBoostingClassifier,
    StackingClassifier, VotingClassifier
)
from sklearn.linear_model import LogisticRegression
```

```{python}
#| label: configuration
#| include: false

# -----------------------------------------------------------------------------
# Configuration and helpers
# -----------------------------------------------------------------------------

# Hardware optimization
N_JOBS = multiprocessing.cpu_count() - 1

# Reproducibility
RANDOM_STATE = 42
CV_FOLDS = 5
N_ITER_SEARCH = 50
TEST_SIZE = 0.20
VAL_SIZE = 0.15

# Text processing
LSA_COMPONENTS = 20
TFIDF_MAX_FEATURES = 500

# Business parameters
COST_PER_CALL = 50
VALUE_PER_SQL = 6000

# SHAP sampling
SHAP_BACKGROUND_SAMPLES = 100
SHAP_TEST_SAMPLES = 200

# Color palette
COL_SUCCESS = '#00534B'   # Teal — positive outcomes
COL_RISK    = '#F05627'   # Orange — gaps / risk
COL_NEUTRAL = '#95a5a6'   # Gray — baseline
COL_ACCENT  = '#2980b9'   # Blue — highlights
COL_GOLD    = '#f39c12'   # Gold — optimal points
COL_PROFIT  = '#27ae60'   # Green — profit
COL_LOWVAL  = '#e74c3c'   # Red — low-value channels
COL_PREMIUM = '#2ecc71'   # Green — premium channels

# Visualization defaults
sns.set_theme(style="whitegrid", context="talk")
plt.rcParams.update({
    'figure.figsize': (10, 6),
    'figure.dpi': 150,
    'axes.titleweight': 'bold',
    'font.family': 'sans-serif'
})

# Table formatting helper
def print_table(data, caption="", fmt="pipe"):
    """Format a DataFrame as a styled markdown table."""
    if isinstance(data, pd.DataFrame):
        print(f"\n**{caption}**\n" if caption else "")
        print(data.to_markdown(index=False))
    else:
        print(data)

# Path configuration
DATA_DIR = here("data")
OUTPUT_DIR = here("output")
CLEANED_DATA_PATH = here("output/Cleaned_QAL_Performance_for_MSBA.csv")
RAW_DATA_PATH = here("data/QAL Performance for MSBA.csv")

DATA_PATH = CLEANED_DATA_PATH if CLEANED_DATA_PATH.exists() else RAW_DATA_PATH
```

```{python}
#| label: catboost-wrapper
#| include: false

# -----------------------------------------------------------------------------
# CatBoost sklearn 1.6+ compatibility wrapper
# -----------------------------------------------------------------------------
# sklearn 1.6 changed __sklearn_tags__ to require dot-notation namespace
# objects. CatBoost does not support this natively, so a thin wrapper is
# needed to use it inside RandomizedSearchCV and StackingClassifier.

CATBOOST_AVAILABLE = False
try:
    from catboost import CatBoostClassifier as CatBoostRaw

    class SklearnCatBoost(BaseEstimator, ClassifierMixin):
        _estimator_type = "classifier"

        def __init__(self, iterations=500, depth=6, learning_rate=0.1,
                     l2_leaf_reg=3, border_count=64, random_state=42,
                     verbose=0, thread_count=1):
            self.iterations = iterations
            self.depth = depth
            self.learning_rate = learning_rate
            self.l2_leaf_reg = l2_leaf_reg
            self.border_count = border_count
            self.random_state = random_state
            self.verbose = verbose
            self.thread_count = thread_count
            self._model = None

        def __sklearn_tags__(self):
            tags = SimpleNamespace()
            tags.estimator_type = "classifier"
            tags.classifier_tags = SimpleNamespace()
            tags.regressor_tags = None
            tags.transformer_tags = None
            tags.input_tags = SimpleNamespace(
                allow_nan=True, pairwise=False,
                one_d_labels=True, two_d_labels=False)
            tags.target_tags = SimpleNamespace(
                required_y=True, one_d_labels=True, two_d_labels=False)
            return tags

        def fit(self, X, y, **fit_params):
            self._model = CatBoostRaw(
                iterations=self.iterations, depth=self.depth,
                learning_rate=self.learning_rate, l2_leaf_reg=self.l2_leaf_reg,
                border_count=self.border_count, random_state=self.random_state,
                verbose=self.verbose, thread_count=self.thread_count,
                allow_writing_files=False)
            self._model.fit(X, y, **fit_params)
            self.classes_ = np.unique(y)
            return self

        def predict(self, X):
            return self._model.predict(X).flatten().astype(int)

        def predict_proba(self, X):
            return self._model.predict_proba(X)

        @property
        def feature_importances_(self):
            return self._model.get_feature_importance()

    CATBOOST_AVAILABLE = True
except ImportError:
    pass

# Other boosting libraries
XGBOOST_AVAILABLE = False
try:
    from xgboost import XGBClassifier
    XGBOOST_AVAILABLE = True
except ImportError:
    pass

LIGHTGBM_AVAILABLE = False
try:
    from lightgbm import LGBMClassifier
    LIGHTGBM_AVAILABLE = True
except ImportError:
    pass

TARGET_ENCODER_AVAILABLE = False
try:
    from sklearn.preprocessing import TargetEncoder
    TARGET_ENCODER_AVAILABLE = True
except ImportError:
    pass

SHAP_AVAILABLE = False
try:
    import shap
    SHAP_AVAILABLE = True
except ImportError:
    pass
```

# Business Problem

MasterControl sells quality management software to regulated industries, primarily through two product lines: **Mx** (manufacturing execution) and **Qx** (quality management). Leads enter the pipeline as Qualified Activity Leads (QALs) and progress through stages: Disqualified, Recycled, SQL, SQO, or Won.

The core challenge is conversion efficiency. Mx converts at approximately 12.7% versus 19.7% for Qx—a 7 percentage-point gap. With a \$50 cost per sales call and \$6,000 value per SQL conversion, the ability to identify which leads are most likely to convert has direct revenue impact.

The goal is not merely prediction accuracy, as only \~15% of leads convert. A naive model could achieve 85% accuracy by predicting "no conversion" for every lead, but this fails to prioritize the pipeline. Instead, leads must be ranked by conversion likelihood using AUC-ROC, enabling the sales team to allocate effort toward the highest-value opportunities.

# Methodology

The CRISP-DM framework structures the analysis:

-   **Data Preparation:** Raw CRM data is loaded, column names are standardized, and missing categoricals are imputed with "Unknown."
-   **Feature Engineering:** Domain-informed features are created based on EDA findings—channel quality tiers, intent strength encoding, title parsing for seniority/function/scope, industry-weighted budget proxies, and role-product alignment scores.
-   **Modeling:** A progression of gradient boosting models is tuned via randomized search with 5-fold stratified cross-validation, then combined in a stacking ensemble.
-   **Evaluation:** AUC-ROC is the primary metric. Profit curves translate model scores into dollar-denominated business impact at various scoring thresholds.

# Data Preparation & Feature Engineering

```{python}
#| label: feature-definitions
#| include: false

# -----------------------------------------------------------------------------
# Feature mappings (domain-informed)
# -----------------------------------------------------------------------------

# Intent strength: ordinal encoding of priority
# "Webinar" P1 leads convert at lower rates than "Contact Us" P1s
INTENT_STRENGTH_MAP = {
    'P1 - Website Pricing': 5,
    'P1 - Contact Us': 5,
    'P1 - Video Demo': 3,
    'P1 - Live Demo': 3,
    'P1 - Webinar Demo': 1,
    'No Priority': 1,
    'Priority 1': 2,
    'Priority 2': 0
}

# Channel efficiency: tiered lead source quality
# External Demand Gen converts at ~2.5%, Direct/Inbound at 18%+
CHANNEL_TIER_MAP = {
    'Direct/Inbound': 'Premium', 'SEO': 'Premium', 'Referrals': 'Premium',
    'Online Ads': 'Standard', 'Directory Listing': 'Standard',
    'Events': 'Standard', 'Outbound Prospecting': 'Standard',
    'Email': 'Low-Value', 'External Demand Gen': 'Low-Value'
}
CHANNEL_NUMERIC_MAP = {'Premium': 3, 'Standard': 2, 'Low-Value': 1, 'Unknown': 2}

# Capital density: industry-weighted budget proxy
INDUSTRY_BUDGET_MULTIPLIER = {
    'Pharma & BioTech': 3.0, 'Blood & Biologics': 2.5,
    'Medical Device': 2.0, 'Non-Life Science': 1.0,
    'Consumer Packaged Goods': 0.8
}
TIER_SIZE_MAP = {'Small': 50, 'Medium': 500, 'Large': 5000}

# Hidden gem signals: leads with missing firmographics that convert well
HIDDEN_GEM_SIGNALS = {
    'manufacturing_model': ['Not Enough Info Found'],
    'industry': ['Non-manufacturing organization']
}

# Role-product alignment
PRODUCT_ROLE_ALIGNMENT = {
    'Mx': ['Op', 'Mfg', 'Manuf', 'Production', 'Plant'],
    'Qx': ['Qual', 'QA', 'QC', 'Compliance', 'Validation']
}

# High-value title bigrams
HIGH_VALUE_BIGRAMS = [
    'continuous improvement', 'document control', 'process engineer',
    'quality systems', 'regulatory affairs', 'quality assurance',
    'validation engineer', 'compliance manager'
]
```

The raw CRM export contains 16,816 QAL records with fields for account attributes (industry, tier, territory), contact attributes (title, priority), channel source, and pipeline stage. The feature engineering pipeline creates six domain-informed signals based on patterns identified during EDA.

```{python}
#| label: data-pipeline

# -----------------------------------------------------------------------------
# Data pipeline
# -----------------------------------------------------------------------------

def clean_and_engineer(filepath):
    """Load raw CRM data and engineer domain-informed features."""

    df = pd.read_csv(filepath)

    # Standardize column names
    df.columns = [c.strip().lower().replace(' ', '_').replace('/', '_').replace('-', '_')
                  for c in df.columns]

    # Target: SQL, SQO, or Won = success
    if 'is_success' not in df.columns:
        df['is_success'] = df['next_stage__c'].isin(['SQL', 'SQO', 'Won']).astype(int)

    # --- Feature 1: Intent Strength ---
    if 'priority' in df.columns:
        df['intent_strength'] = df['priority'].map(INTENT_STRENGTH_MAP).fillna(1)
    else:
        df['intent_strength'] = 1

    # --- Feature 2: Channel Efficiency ---
    channel_col = 'last_tactic_campaign_channel' if 'last_tactic_campaign_channel' in df.columns else 'lead_source'
    if channel_col in df.columns:
        df['channel_tier'] = df[channel_col].map(CHANNEL_TIER_MAP).fillna('Standard')
        df['channel_efficiency'] = df['channel_tier'].map(CHANNEL_NUMERIC_MAP)
    else:
        df['channel_tier'] = 'Standard'
        df['channel_efficiency'] = 2

    # --- Feature 3: Hidden Gem Flag ---
    model_col = 'acct_manufacturing_model' if 'acct_manufacturing_model' in df.columns else None
    industry_col = 'acct_target_industry' if 'acct_target_industry' in df.columns else None
    site_col = 'acct_primary_site_function' if 'acct_primary_site_function' in df.columns else None

    gem_mask = pd.Series(False, index=df.index)
    if model_col:
        gem_mask |= df[model_col].str.contains('Not Enough Info', case=False, na=False)
    if site_col:
        gem_mask |= df[site_col].str.contains('Non-manufacturing', case=False, na=False)
    if industry_col:
        gem_mask |= df[industry_col].str.contains('Non-manufacturing', case=False, na=False)
    df['is_hidden_gem'] = gem_mask.astype(int)

    # --- Feature 4: Capital Density Score ---
    tier_col = 'acct_tier_rollup' if 'acct_tier_rollup' in df.columns else None
    if industry_col and tier_col:
        df['_ind_mult'] = df[industry_col].map(
            lambda x: next((v for k, v in INDUSTRY_BUDGET_MULTIPLIER.items()
                           if k.lower() in str(x).lower()), 1.0))
        df['_tier_size'] = df[tier_col].map(TIER_SIZE_MAP).fillna(500)
        df['capital_density_score'] = df['_ind_mult'] * df['_tier_size']
        df['capital_density_log'] = np.log1p(df['capital_density_score'])
        df.drop(columns=['_ind_mult', '_tier_size'], errors='ignore', inplace=True)
    else:
        df['capital_density_score'] = 500
        df['capital_density_log'] = np.log1p(500)

    # --- Feature 5: Role-Product Match ---
    title_col = 'contact_lead_title' if 'contact_lead_title' in df.columns else None
    product_col = 'product_segment' if 'product_segment' in df.columns else 'solution_rollup'

    # Product segmentation (if not already present)
    if 'product_segment' not in df.columns:
        df['product_segment'] = df['solution_rollup'].apply(
            lambda s: 'Mx' if str(s) == 'Mx' else ('Qx' if str(s) == 'Qx' else 'Other'))

    if title_col and product_col in df.columns:
        def _role_match(row):
            title = str(row[title_col]).lower() if pd.notna(row[title_col]) else ''
            product = str(row[product_col]) if pd.notna(row[product_col]) else ''
            if product in PRODUCT_ROLE_ALIGNMENT:
                return int(any(kw.lower() in title for kw in PRODUCT_ROLE_ALIGNMENT[product]))
            return 0
        df['role_product_match'] = df.apply(_role_match, axis=1)
    else:
        df['role_product_match'] = 0

    # --- Feature 6: Title Bigrams ---
    if title_col and title_col in df.columns:
        for bigram in HIGH_VALUE_BIGRAMS:
            df['has_' + bigram.replace(' ', '_')] = (
                df[title_col].str.lower().str.contains(bigram, na=False).astype(int))
        bigram_cols = [c for c in df.columns if c.startswith('has_')]
        df['title_bigram_count'] = df[bigram_cols].sum(axis=1)
    else:
        df['title_bigram_count'] = 0

    # --- Title Parsing (Seniority, Function, Scope) ---
    if 'title_seniority' not in df.columns and title_col and title_col in df.columns:
        def _seniority(t):
            if pd.isna(t): return 'Unknown'
            t = str(t).lower()
            if re.search(r'\b(ceo|cfo|coo|cto|cio|chief|c-level|president)\b', t): return 'C-Suite'
            if re.search(r'\b(svp|senior vice president|evp)\b', t): return 'SVP'
            if re.search(r'\b(vp|vice president)\b', t): return 'VP'
            if re.search(r'\b(director|head of)\b', t): return 'Director'
            if re.search(r'\b(manager|mgr|supervisor|lead)\b', t): return 'Manager'
            if re.search(r'\b(analyst|engineer|specialist|associate|coordinator)\b', t): return 'IC'
            return 'Other'

        def _function(t):
            if pd.isna(t): return 'Unknown'
            t = str(t).lower()
            if re.search(r'\b(quality|qa|qc|qms|compliance|validation|capa)\b', t): return 'Quality'
            if re.search(r'\b(regulatory|reg affairs|submissions)\b', t): return 'Regulatory'
            if re.search(r'\b(manufacturing|production|operations|ops|plant|supply)\b', t): return 'Mfg/Ops'
            if re.search(r'\b(it|information tech|software|systems|data)\b', t): return 'IT'
            if re.search(r'\b(r&d|research|development|scientist|clinical|lab)\b', t): return 'R&D'
            if re.search(r'\b(project|program|pmo)\b', t): return 'PMO'
            return 'Other'

        def _scope(t):
            if pd.isna(t): return 'Standard'
            t = str(t).lower()
            if re.search(r'\b(global|worldwide|international|corporate|enterprise)\b', t): return 'Global'
            if re.search(r'\b(regional|division|group)\b', t): return 'Regional'
            if re.search(r'\b(site|plant|facility|local)\b', t): return 'Site'
            return 'Standard'

        df['title_seniority'] = df[title_col].apply(_seniority)
        df['title_function'] = df[title_col].apply(_function)
        df['title_scope'] = df[title_col].apply(_scope)

    # Decision maker flag
    if 'is_decision_maker' not in df.columns:
        df['is_decision_maker'] = df['title_seniority'].isin(
            ['C-Suite', 'SVP', 'VP', 'Director']).astype(int)

    # Temporal features
    if 'cohort_date' in df.columns or 'qal_cohort_date' in df.columns:
        cohort_src = 'qal_cohort_date' if 'qal_cohort_date' in df.columns else 'cohort_date'
        df['cohort_date'] = pd.to_datetime(df[cohort_src], errors='coerce')
        if 'lead_age_days' not in df.columns:
            df['lead_age_days'] = (df['cohort_date'].max() - df['cohort_date']).dt.days

    # Velocity tiers
    if 'lead_age_days' in df.columns:
        df['velocity_tier'] = pd.cut(
            df['lead_age_days'].fillna(0), bins=[-1, 30, 60, 90, 180, 9999],
            labels=['Hot', 'Warm', 'Cooling', 'Cold', 'Stale']).astype(str)
        df['is_fresh'] = (df['lead_age_days'] <= 30).astype(int)
        df['is_stale'] = (df['lead_age_days'] > 180).astype(int)

    # Interaction features
    sen_col = 'title_seniority' if 'title_seniority' in df.columns else None
    ind_col = 'acct_target_industry' if 'acct_target_industry' in df.columns else None
    mod_col = 'acct_manufacturing_model' if 'acct_manufacturing_model' in df.columns else None

    if sen_col and ind_col and mod_col:
        df['seniority_x_industry'] = df[sen_col].astype(str) + '_' + df[ind_col].astype(str)
        df['seniority_x_model'] = df[sen_col].astype(str) + '_' + df[mod_col].astype(str)
        df['industry_x_model'] = df[ind_col].astype(str) + '_' + df[mod_col].astype(str)
        df['power_trio'] = df[sen_col].astype(str) + '_' + df[ind_col].astype(str) + '_' + df[mod_col].astype(str)

        senior = df[sen_col].isin(['Director', 'VP', 'SVP', 'C-Suite'])
        pharma = df[ind_col].str.contains('Pharma|Life|Bio', case=False, na=False)
        inhouse = df[mod_col].str.contains('In-House|In House|Inhouse', case=False, na=False)
        df['is_golden_segment'] = (senior & pharma & inhouse).astype(int)
        df['is_senior_pharma'] = (senior & pharma).astype(int)

    if 'title_scope' in df.columns:
        df['is_global_scope'] = (df['title_scope'] == 'Global').astype(int)

    # Fill missing categoricals
    for col in ['acct_manufacturing_model', 'acct_primary_site_function',
                'acct_target_industry', 'acct_territory_rollup',
                'title_seniority', 'title_function', 'title_scope', 'channel_tier']:
        if col in df.columns:
            df[col] = df[col].fillna('Unknown')

    return df

df = clean_and_engineer(DATA_PATH)
```

The table below summarizes the six engineered features and their observed relationship with the target variable.

```{python}
#| label: feature-summary

# Engineered feature validation
feature_checks = []
for feat, label in [
    ('intent_strength', 'Intent Strength'),
    ('channel_efficiency', 'Channel Efficiency'),
    ('is_hidden_gem', 'Hidden Gem Flag'),
    ('capital_density_log', 'Capital Density (log)'),
    ('role_product_match', 'Role-Product Match'),
    ('title_bigram_count', 'Title Bigram Count')
]:
    if feat in df.columns:
        corr = df[feat].corr(df['is_success'])
        feature_checks.append({
            'Feature': label,
            'Correlation with Target': f'{corr:+.4f}',
            'Mean (Success)': f'{df.loc[df["is_success"]==1, feat].mean():.2f}',
            'Mean (Failure)': f'{df.loc[df["is_success"]==0, feat].mean():.2f}'
        })

print_table(pd.DataFrame(feature_checks), caption="Engineered Feature Validation")
```

```{python}
#| label: dataset-summary

# Dataset dimensions
summary_data = {
    'Metric': ['Total Leads', 'Target Rate (SQL+)', 'Mx Leads', 'Qx Leads',
               'Recycled (Near-Miss)', 'Decision Makers', 'Features Engineered'],
    'Value': [
        f'{len(df):,}',
        f'{df["is_success"].mean():.1%}',
        f'{(df["product_segment"]=="Mx").sum():,}',
        f'{(df["product_segment"]=="Qx").sum():,}',
        f'{(df["next_stage__c"]=="Recycled").sum():,}',
        f'{df["is_decision_maker"].sum():,} ({df["is_decision_maker"].mean():.1%})',
        '6 new + 8 interaction/flag features'
    ]
}
print_table(pd.DataFrame(summary_data), caption="Dataset Overview")
```

## Channel Tier Conversion

The channel tier feature captures one of the strongest patterns in the data. Premium channels (Direct/Inbound, SEO, Referrals) convert at substantially higher rates than low-value channels (External Demand Gen, Email), which account for roughly a third of pipeline volume.

```{python}
#| label: channel-tier-plot

fig, ax = plt.subplots(figsize=(8, 5))

channel_conv = df.groupby('channel_tier')['is_success'].agg(['mean', 'count'])
channel_conv = channel_conv.reindex(['Premium', 'Standard', 'Low-Value'])

colors = [COL_PREMIUM, COL_NEUTRAL, COL_LOWVAL]
bars = ax.bar(channel_conv.index, channel_conv['mean'], color=colors, edgecolor='white', linewidth=1.5)

for i, (idx, row) in enumerate(channel_conv.iterrows()):
    ax.text(i, row['mean'] + 0.008, f'{row["mean"]:.1%}', ha='center', fontweight='bold', fontsize=12)
    ax.text(i, row['mean'] / 2, f'n={int(row["count"]):,}', ha='center', color='white', fontsize=9)

ax.axhline(y=df['is_success'].mean(), color='black', linestyle='--', alpha=0.4,
           label=f'Baseline ({df["is_success"].mean():.1%})')
ax.set_ylabel('Conversion Rate')
ax.set_xlabel('Channel Tier')
ax.set_title('Conversion Rate by Channel Tier',
             fontweight='bold', fontsize=13)
ax.set_ylim(0, channel_conv['mean'].max() * 1.3)
ax.legend(loc='upper right', fontsize=9)
sns.despine()
plt.tight_layout()
plt.savefig(here("output") / "channel_tier_conversion.png", dpi=200, bbox_inches='tight')
plt.show()
```

Low-value channels convert at roughly one-fifth the rate of premium channels. This pattern alone suggests significant efficiency gains from deprioritizing or re-routing these leads.

# Model Analysis

The modeling phase establishes a baseline against the \~15% overall conversion rate. Five candidate algorithms are tuned, ranked on a held-out validation set, and the top three are combined in a stacking ensemble.

```{python}
#| label: feature-matrix
#| include: false

# -----------------------------------------------------------------------------
# Feature matrix construction
# -----------------------------------------------------------------------------

def prepare_feature_matrix(df):
    """Assemble the feature matrix for modeling."""
    y = df['is_success'].values

    categorical_features = [c for c in [
        'title_seniority', 'title_function', 'title_scope',
        'acct_target_industry', 'acct_manufacturing_model',
        'acct_primary_site_function', 'acct_territory_rollup',
        'product_segment', 'channel_tier'
    ] if c in df.columns]

    interaction_features = [c for c in [
        'seniority_x_industry', 'seniority_x_model',
        'industry_x_model', 'power_trio'
    ] if c in df.columns]

    velocity_cats = [c for c in ['velocity_tier'] if c in df.columns]

    all_categoricals = categorical_features + interaction_features + velocity_cats

    numeric_features = [c for c in [
        'lead_age_days', 'is_decision_maker', 'is_fresh', 'is_stale',
        'is_golden_segment', 'is_senior_pharma', 'is_global_scope',
        'intent_strength', 'channel_efficiency', 'is_hidden_gem',
        'capital_density_log', 'role_product_match', 'title_bigram_count'
    ] if c in df.columns]

    bigram_cols = [c for c in df.columns if c.startswith('has_')]
    numeric_features.extend(bigram_cols)
    if 'record_completeness' in df.columns:
        numeric_features.append('record_completeness')

    text_col = 'contact_lead_title' if 'contact_lead_title' in df.columns else None

    X = df[all_categoricals + numeric_features].copy()
    text_data = df[text_col].fillna('') if text_col else None

    return X, y, text_data, all_categoricals, numeric_features

X, y, text_data, cat_cols, num_cols = prepare_feature_matrix(df)
```

```{python}
#| label: data-split
#| include: false

# -----------------------------------------------------------------------------
# Stratified train / validation / test split
# -----------------------------------------------------------------------------

X_temp, X_test, y_temp, y_test = train_test_split(
    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y)
X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp, test_size=VAL_SIZE/(1-TEST_SIZE),
    random_state=RANDOM_STATE, stratify=y_temp)

if text_data is not None:
    text_temp, text_test = train_test_split(
        text_data, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y)
    text_train, text_val = train_test_split(
        text_temp, test_size=VAL_SIZE/(1-TEST_SIZE),
        random_state=RANDOM_STATE, stratify=y_temp)
else:
    text_train = text_val = text_test = None
```

```{python}
#| label: encoding
#| include: false

# -----------------------------------------------------------------------------
# Target encoding + label encoding + LSA
# -----------------------------------------------------------------------------

target_encode_cols = [c for c in cat_cols if X_train[c].nunique() > 10]
standard_encode_cols = [c for c in cat_cols if c not in target_encode_cols]

# Manual target encoder (fallback)
class ManualTargetEncoder(BaseEstimator, TransformerMixin):
    def __init__(self, columns=None, smoothing=10):
        self.columns = columns
        self.smoothing = smoothing
        self.encoding_maps_ = {}
        self.global_mean_ = None

    def fit(self, X, y):
        X = pd.DataFrame(X) if not isinstance(X, pd.DataFrame) else X
        y = np.array(y)
        self.global_mean_ = y.mean()
        cols = self.columns or X.select_dtypes(include=['object', 'category']).columns.tolist()
        for col in cols:
            if col in X.columns:
                tmp = pd.DataFrame({'col': X[col].astype(str), 'target': y})
                agg = tmp.groupby('col')['target'].agg(['mean', 'count'])
                smoothed = (agg['count'] * agg['mean'] + self.smoothing * self.global_mean_) / (agg['count'] + self.smoothing)
                self.encoding_maps_[col] = smoothed.to_dict()
        return self

    def transform(self, X):
        X = pd.DataFrame(X).copy() if not isinstance(X, pd.DataFrame) else X.copy()
        for col, mapping in self.encoding_maps_.items():
            if col in X.columns:
                X[col + '_encoded'] = X[col].astype(str).map(mapping).fillna(self.global_mean_)
        return X

# Apply target encoding
if TARGET_ENCODER_AVAILABLE and len(target_encode_cols) > 0:
    target_encoder = TargetEncoder(smooth='auto', target_type='binary')
    X_train_te, X_val_te, X_test_te = X_train.copy(), X_val.copy(), X_test.copy()
    te_train = target_encoder.fit_transform(X_train[target_encode_cols], y_train)
    te_val = target_encoder.transform(X_val[target_encode_cols])
    te_test = target_encoder.transform(X_test[target_encode_cols])
    for i, col in enumerate(target_encode_cols):
        X_train_te[col] = te_train[:, i]
        X_val_te[col] = te_val[:, i]
        X_test_te[col] = te_test[:, i]
elif len(target_encode_cols) > 0:
    manual_enc = ManualTargetEncoder(columns=target_encode_cols, smoothing=10)
    X_train_te = manual_enc.fit_transform(X_train, y_train)
    X_val_te = manual_enc.transform(X_val)
    X_test_te = manual_enc.transform(X_test)
    for col in target_encode_cols:
        if col + '_encoded' in X_train_te.columns:
            for df_te in [X_train_te, X_val_te, X_test_te]:
                df_te[col] = df_te[col + '_encoded']
else:
    X_train_te, X_val_te, X_test_te = X_train.copy(), X_val.copy(), X_test.copy()

# Label encoding
label_encoders = {}
for col in standard_encode_cols:
    le = LabelEncoder()
    X_train_te[col] = le.fit_transform(X_train_te[col].astype(str))
    safe_tx = lambda s, enc=le: s.astype(str).apply(
        lambda x: enc.transform([x])[0] if x in enc.classes_ else 0)
    X_val_te[col] = safe_tx(X_val_te[col])
    X_test_te[col] = safe_tx(X_test_te[col])
    label_encoders[col] = le

# LSA for title text
if text_train is not None:
    tfidf = TfidfVectorizer(max_features=TFIDF_MAX_FEATURES, ngram_range=(1, 2),
                            stop_words='english', min_df=5)
    svd = TruncatedSVD(n_components=LSA_COMPONENTS, random_state=RANDOM_STATE)
    lsa_train = svd.fit_transform(tfidf.fit_transform(text_train))
    lsa_val = svd.transform(tfidf.transform(text_val))
    lsa_test = svd.transform(tfidf.transform(text_test))
    for i in range(LSA_COMPONENTS):
        col = f'lsa_{i}'
        X_train_te[col] = lsa_train[:, i]
        X_val_te[col] = lsa_val[:, i]
        X_test_te[col] = lsa_test[:, i]

# Final numeric conversion
for col in X_train_te.columns:
    if X_train_te[col].dtype == 'object':
        le = LabelEncoder()
        X_train_te[col] = le.fit_transform(X_train_te[col].astype(str))
        safe_enc = lambda s, enc=le: s.astype(str).apply(
            lambda x: enc.transform([x])[0] if x in enc.classes_ else 0)
        X_val_te[col] = safe_enc(X_val_te[col])
        X_test_te[col] = safe_enc(X_test_te[col])

X_train_te = X_train_te.fillna(0)
X_val_te = X_val_te.fillna(0)
X_test_te = X_test_te.fillna(0)
```

A 70/15/15 stratified split ensures all partitions maintain the same class balance. The split dimensions are shown below.

```{python}
#| label: split-summary

split_summary = pd.DataFrame({
    'Partition': ['Train', 'Validation', 'Test'],
    'Rows': [f'{len(X_train):,}', f'{len(X_val):,}', f'{len(X_test):,}'],
    'Positive Rate': [f'{y_train.mean():.1%}', f'{y_val.mean():.1%}', f'{y_test.mean():.1%}'],
    'Features': [X_train_te.shape[1]] * 3
})
print_table(split_summary, caption="Data Partition Summary")
```

## Candidate Models

Five algorithms are evaluated. Each is tuned with randomized search (50 iterations, 5-fold stratified CV, scored on AUC-ROC). Models use single-threaded internals while the outer search loop parallelizes across `N-1` cores to prevent thread contention.

```{python}
#| label: model-training

# -----------------------------------------------------------------------------
# Model definitions and hyperparameter search
# -----------------------------------------------------------------------------

models = {}
param_grids = {}
pos_weight = (y_train == 0).sum() / (y_train == 1).sum()

if CATBOOST_AVAILABLE:
    models['CatBoost'] = SklearnCatBoost(random_state=RANDOM_STATE, verbose=0, thread_count=1)
    param_grids['CatBoost'] = {
        'depth': [4, 6, 8, 10], 'learning_rate': [0.01, 0.03, 0.05, 0.1],
        'iterations': [300, 500, 800], 'l2_leaf_reg': [1, 3, 5, 7],
        'border_count': [32, 64, 128]
    }

if XGBOOST_AVAILABLE:
    models['XGBoost'] = XGBClassifier(random_state=RANDOM_STATE, n_jobs=1, eval_metric='logloss')
    param_grids['XGBoost'] = {
        'max_depth': [4, 6, 8, 10], 'learning_rate': [0.01, 0.03, 0.05, 0.1],
        'n_estimators': [300, 500, 800], 'scale_pos_weight': [1, pos_weight],
        'subsample': [0.7, 0.8, 0.9, 1.0], 'colsample_bytree': [0.7, 0.8, 0.9, 1.0],
        'reg_alpha': [0, 0.1, 0.5], 'reg_lambda': [1, 2, 5]
    }

if LIGHTGBM_AVAILABLE:
    models['LightGBM'] = LGBMClassifier(random_state=RANDOM_STATE, n_jobs=1, verbose=-1)
    param_grids['LightGBM'] = {
        'num_leaves': [31, 63, 127, 255], 'learning_rate': [0.01, 0.03, 0.05, 0.1],
        'n_estimators': [300, 500, 800], 'class_weight': ['balanced', None],
        'subsample': [0.7, 0.8, 0.9, 1.0], 'colsample_bytree': [0.7, 0.8, 0.9, 1.0],
        'reg_alpha': [0, 0.1, 0.5], 'reg_lambda': [1, 2, 5]
    }

models['GradientBoosting'] = GradientBoostingClassifier(random_state=RANDOM_STATE)
param_grids['GradientBoosting'] = {
    'n_estimators': [100, 200, 300], 'max_depth': [4, 6, 8],
    'learning_rate': [0.05, 0.1, 0.2], 'subsample': [0.8, 0.9, 1.0]
}

models['RandomForest'] = RandomForestClassifier(
    random_state=RANDOM_STATE, n_jobs=1, class_weight='balanced')
param_grids['RandomForest'] = {
    'n_estimators': [100, 200, 300], 'max_depth': [10, 15, 20, None],
    'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]
}

# Run search
cv = StratifiedKFold(n_splits=CV_FOLDS, shuffle=True, random_state=RANDOM_STATE)
best_models = {}
cv_results = {}

for name, model in models.items():
    search = RandomizedSearchCV(
        estimator=model, param_distributions=param_grids[name],
        n_iter=N_ITER_SEARCH, cv=cv, scoring='roc_auc',
        n_jobs=N_JOBS, random_state=RANDOM_STATE, verbose=0)
    search.fit(X_train_te, y_train)
    best_models[name] = search.best_estimator_
    cv_results[name] = {'best_score': search.best_score_, 'best_params': search.best_params_}

# Validation evaluation
val_results = {}
for name, model in best_models.items():
    probs = model.predict_proba(X_val_te)[:, 1]
    val_results[name] = {'auc': roc_auc_score(y_val, probs), 'probs': probs}

val_ranking = sorted(val_results.items(), key=lambda x: x[1]['auc'], reverse=True)
```

```{python}
#| label: tournament-results

# Model comparison table
tournament_df = pd.DataFrame([
    {'Model': name,
     'CV AUC (5-fold)': f'{cv_results[name]["best_score"]:.4f}',
     'Validation AUC': f'{val_results[name]["auc"]:.4f}'}
    for name in best_models.keys()
]).sort_values('Validation AUC', ascending=False)

print_table(tournament_df, caption="Model Comparison")
```

## Stacking Ensemble

The top three models from the validation ranking serve as base learners in a stacking ensemble with a logistic regression meta-learner. This approach captures complementary predictive patterns across algorithms.

```{python}
#| label: stacking

# Stacking ensemble
top_3_names = [name for name, _ in val_ranking[:3]]
stacking_clf = StackingClassifier(
    estimators=[(name, best_models[name]) for name in top_3_names],
    final_estimator=LogisticRegression(
        random_state=RANDOM_STATE, max_iter=1000, class_weight='balanced'),
    cv=CV_FOLDS, stack_method='predict_proba', n_jobs=N_JOBS, passthrough=False)

stacking_clf.fit(X_train_te, y_train)
stack_val_probs = stacking_clf.predict_proba(X_val_te)[:, 1]
stack_val_auc = roc_auc_score(y_val, stack_val_probs)

best_models['StackingEnsemble'] = stacking_clf
val_results['StackingEnsemble'] = {'auc': stack_val_auc, 'probs': stack_val_probs}

# Select champion
champion_name = max(val_results.items(), key=lambda x: x[1]['auc'])[0]
champion_model = best_models[champion_name]
```

```{python}
#| label: stacking-result

stack_vs_best = stack_val_auc - val_ranking[0][1]['auc']
stack_result = pd.DataFrame({
    'Metric': ['Stacking AUC', f'Best Individual ({val_ranking[0][0]})', 'Improvement', 'Selected Model'],
    'Value': [f'{stack_val_auc:.4f}', f'{val_ranking[0][1]["auc"]:.4f}',
              f'{stack_vs_best:+.4f}', champion_name]
})
print_table(stack_result, caption="Ensemble vs Best Individual")
```

## Test Set Evaluation

The selected model is evaluated on the held-out test set, which has not been used during training or model selection.

```{python}
#| label: test-evaluation

# Final test evaluation
test_probs = champion_model.predict_proba(X_test_te)[:, 1]
test_preds = (test_probs >= 0.5).astype(int)

test_auc = roc_auc_score(y_test, test_probs)
test_ap = average_precision_score(y_test, test_probs)
test_brier = brier_score_loss(y_test, test_probs)
test_logloss = log_loss(y_test, test_probs)

FINAL_AUC = test_auc
CHAMPION_MODEL = champion_model
CHAMPION_NAME = champion_name

metrics_df = pd.DataFrame({
    'Metric': ['AUC-ROC', 'Average Precision', 'Brier Score', 'Log Loss'],
    'Value': [f'{test_auc:.4f}', f'{test_ap:.4f}', f'{test_brier:.4f}', f'{test_logloss:.4f}']
})
print_table(metrics_df, caption=f"Test Set Performance ({CHAMPION_NAME})")
```

```{python}
#| label: roc-curve

# ROC curve
fig, ax = plt.subplots(figsize=(8, 7))
fpr, tpr, thresholds = roc_curve(y_test, test_probs)
ax.plot(fpr, tpr, color=COL_SUCCESS, linewidth=2.5,
        label=f'{CHAMPION_NAME} (AUC = {FINAL_AUC:.3f})')
ax.plot([0, 1], [0, 1], 'k--', alpha=0.4, label='Random (AUC = 0.500)')
ax.fill_between(fpr, 0, tpr, alpha=0.15, color=COL_SUCCESS)
ax.set_xlabel('False Positive Rate')
ax.set_ylabel('True Positive Rate')
ax.set_title('ROC Curve: Discriminative Power', fontweight='bold', fontsize=13)
ax.legend(loc='lower right')
ax.set_xlim(-0.02, 1.02)
ax.set_ylim(-0.02, 1.02)
sns.despine()
plt.tight_layout()
plt.savefig(here("output") / "roc_curve.png", dpi=200, bbox_inches='tight')
plt.show()
```

The ROC curve confirms that the model separates converters from non-converters substantially better than random. The area between the model curve and the diagonal represents the predictive lift available for lead prioritization.

# Profit Analysis

Predictive accuracy is necessary but insufficient. This section translates model scores into dollar-denominated business impact by calculating profit at every possible scoring threshold.

```{python}
#| label: profit-curve
#| include: false

# Profit curve calculation
def calculate_profit_curve(y_true, y_probs, cost=COST_PER_CALL, value=VALUE_PER_SQL):
    order = np.argsort(y_probs)[::-1]
    y_sorted, probs_sorted = y_true[order], y_probs[order]
    n = len(y_true)
    cumsum = np.cumsum(y_sorted)

    results = []
    for k in range(1, n + 1):
        results.append({
            'threshold': probs_sorted[k-1],
            'n_calls': k, 'n_sqls': cumsum[k-1],
            'revenue': cumsum[k-1] * value, 'cost': k * cost,
            'profit': cumsum[k-1] * value - k * cost,
            'pct_population': k / n,
            'pct_sqls_captured': cumsum[k-1] / y_true.sum() if y_true.sum() > 0 else 0,
            'lift': (cumsum[k-1] / k) / (y_true.sum() / n) if k > 0 else 0
        })
    return pd.DataFrame(results)

profit_df = calculate_profit_curve(y_test, test_probs)
opt = profit_df.iloc[profit_df['profit'].idxmax()]

OPTIMAL_THRESHOLD = opt['threshold']
MAX_PROFIT = opt['profit']
OPTIMAL_CALLS = opt['n_calls']
OPTIMAL_SQLS = opt['n_sqls']
OPTIMAL_PCT_POP = opt['pct_population']
OPTIMAL_PCT_CAPTURE = opt['pct_sqls_captured']
```

```{python}
#| label: profit-table

profit_summary = pd.DataFrame({
    'Metric': ['Optimal Score Threshold', 'Leads to Contact', 'SQLs Captured',
               'Population Contacted', 'SQL Capture Rate', 'Total Cost',
               'Total Revenue', 'Net Profit', 'Lift vs Random'],
    'Value': [f'{OPTIMAL_THRESHOLD:.3f}', f'{int(OPTIMAL_CALLS):,}', f'{int(OPTIMAL_SQLS):,}',
              f'{OPTIMAL_PCT_POP:.1%}', f'{OPTIMAL_PCT_CAPTURE:.1%}',
              f'${int(OPTIMAL_CALLS) * COST_PER_CALL:,.0f}',
              f'${int(OPTIMAL_SQLS) * VALUE_PER_SQL:,.0f}',
              f'${MAX_PROFIT:,.0f}',
              f'{OPTIMAL_PCT_CAPTURE/OPTIMAL_PCT_POP:.1f}x']
})
print_table(profit_summary, caption="Optimal Profit Configuration")
```

```{python}
#| label: profit-visualization

fig, axes = plt.subplots(2, 2, figsize=(10, 8))

# Profit curve
ax1 = axes[0, 0]
ax1.plot(profit_df['pct_population'] * 100, profit_df['profit'] / 1000,
         color=COL_PROFIT, linewidth=2)
ax1.axvline(x=OPTIMAL_PCT_POP * 100, color=COL_GOLD, linestyle='--',
            label=f'Optimal: {OPTIMAL_PCT_POP:.1%}')
ax1.scatter([OPTIMAL_PCT_POP * 100], [MAX_PROFIT / 1000],
            color=COL_GOLD, s=120, zorder=5, marker='*')
ax1.fill_between(profit_df['pct_population'] * 100, 0, profit_df['profit'] / 1000,
                 alpha=0.2, color=COL_PROFIT)
ax1.set_xlabel('% of Leads Contacted')
ax1.set_ylabel('Profit ($K)')
ax1.set_title('Profit Curve', fontweight='bold')
ax1.legend(fontsize=9)
ax1.set_xlim(0, 100)

# Cumulative gains
ax2 = axes[0, 1]
ax2.plot(profit_df['pct_population'] * 100, profit_df['pct_sqls_captured'] * 100,
         color=COL_SUCCESS, linewidth=2, label='Model')
ax2.plot([0, 100], [0, 100], 'k--', alpha=0.4, label='Random')
ax2.axhline(y=90, color=COL_GOLD, linestyle=':', alpha=0.6, label='90% Capture')
ax2.fill_between(profit_df['pct_population'] * 100,
                 profit_df['pct_population'] * 100,
                 profit_df['pct_sqls_captured'] * 100,
                 alpha=0.2, color=COL_SUCCESS)
ax2.set_xlabel('% of Leads Contacted')
ax2.set_ylabel('% of SQLs Captured')
ax2.set_title('Cumulative Gains', fontweight='bold')
ax2.legend(loc='lower right', fontsize=9)
ax2.set_xlim(0, 100); ax2.set_ylim(0, 100)

# Lift chart
ax3 = axes[1, 0]
ax3.plot(profit_df['pct_population'] * 100, profit_df['lift'],
         color=COL_ACCENT, linewidth=2)
ax3.axhline(y=1, color='gray', linestyle='--', alpha=0.4, label='Baseline (1.0x)')
ax3.fill_between(profit_df['pct_population'] * 100, 1, profit_df['lift'],
                 where=profit_df['lift'] > 1, alpha=0.2, color=COL_SUCCESS)
ax3.set_xlabel('% of Leads Contacted')
ax3.set_ylabel('Lift (vs Random)')
ax3.set_title('Lift Chart', fontweight='bold')
ax3.legend(fontsize=9)
ax3.set_xlim(0, 100)

# Profit by decile
ax4 = axes[1, 1]
decile_profits = []
for i in range(10):
    s, e = i * 0.1, (i + 1) * 0.1
    mask = (profit_df['pct_population'] > s) & (profit_df['pct_population'] <= e)
    if mask.any():
        row = profit_df[mask].iloc[-1]
        prev = profit_df[profit_df['pct_population'] <= s].iloc[-1]['profit'] if i > 0 else 0
        decile_profits.append((row['profit'] - prev) / 1000)
    else:
        decile_profits.append(0)

colors = [COL_SUCCESS if p > 0 else COL_RISK for p in decile_profits]
ax4.bar(range(1, 11), decile_profits, color=colors, edgecolor='white')
ax4.axhline(y=0, color='black', linewidth=0.8)
ax4.set_xlabel('Decile (1 = Highest Score)')
ax4.set_ylabel('Incremental Profit ($K)')
ax4.set_title('Profit by Decile', fontweight='bold')
ax4.set_xticks(range(1, 11))

for ax in axes.flat:
    sns.despine(ax=ax)

plt.tight_layout()
plt.savefig(here("output") / "profit_analysis.png", dpi=200, bbox_inches='tight')
plt.show()
```

The profit curve peaks when contacting roughly {OPTIMAL_PCT_POP:.0%} of leads ranked by model score. Beyond this point, marginal leads cost more to pursue than they return. The decile chart confirms that the bottom half of the scored funnel generates negative incremental profit.

# SHAP Explainability

```{python}
#| label: shap-analysis

if SHAP_AVAILABLE:
    np.random.seed(RANDOM_STATE)
    bg_idx = np.random.choice(len(X_train_te), min(SHAP_BACKGROUND_SAMPLES, len(X_train_te)), replace=False)
    test_idx = np.random.choice(len(X_test_te), min(SHAP_TEST_SAMPLES, len(X_test_te)), replace=False)

    X_bg = X_train_te.iloc[bg_idx]
    X_explain = X_test_te.iloc[test_idx]

    try:
        if CHAMPION_NAME in ['CatBoost', 'XGBoost', 'LightGBM', 'GradientBoosting', 'RandomForest']:
            base = CHAMPION_MODEL._model if CHAMPION_NAME == 'CatBoost' and hasattr(CHAMPION_MODEL, '_model') else CHAMPION_MODEL
            explainer = shap.TreeExplainer(base)
            shap_values = explainer.shap_values(X_explain)
            if isinstance(shap_values, list):
                shap_values = shap_values[1]
        elif CHAMPION_NAME == 'StackingEnsemble':
            best_base_name = top_3_names[0]
            best_base = best_models[best_base_name]
            base = best_base._model if best_base_name == 'CatBoost' and hasattr(best_base, '_model') else best_base
            explainer = shap.TreeExplainer(base)
            shap_values = explainer.shap_values(X_explain)
            if isinstance(shap_values, list):
                shap_values = shap_values[1]
        else:
            explainer = shap.KernelExplainer(
                lambda x: CHAMPION_MODEL.predict_proba(x)[:, 1], X_bg)
            shap_values = explainer.shap_values(X_explain, nsamples=100)

        fig, ax = plt.subplots(figsize=(10, 8))
        shap.summary_plot(shap_values, X_explain, plot_type="bar", show=False, max_display=15)
        plt.title(f'Feature Importance (SHAP): {CHAMPION_NAME}', fontweight='bold', fontsize=13)
        plt.tight_layout()
        plt.savefig(here("output") / "shap_importance.png", dpi=200, bbox_inches='tight')
        plt.show()

        fig, ax = plt.subplots(figsize=(10, 10))
        shap.summary_plot(shap_values, X_explain, show=False, max_display=15)
        plt.title('SHAP Value Distribution', fontweight='bold', fontsize=13)
        plt.tight_layout()
        plt.savefig(here("output") / "shap_distribution.png", dpi=200, bbox_inches='tight')
        plt.show()

    except Exception as e:
        print(f"SHAP analysis could not be completed: {e}")
```

SHAP values decompose each prediction into individual feature contributions, making the model's decision logic transparent for sponsor discussions. The bar chart shows aggregate importance, while the beeswarm plot reveals the direction and magnitude of each feature's effect.

# Sponsor Q&A Validation

Each strategic claim is validated against the held-out test set to ensure the recommendations presented to the sponsor are data-backed.

```{python}
#| label: sponsor-validation

# Build validation set with original features
test_indices = X_test.index
validation_df = df.loc[test_indices].copy()
validation_df['actual'] = y_test
validation_df['score'] = test_probs
baseline = validation_df['actual'].mean()

questions = []

# Q1: Low-value channels
if 'channel_tier' in validation_df.columns:
    lv = validation_df[validation_df['channel_tier'] == 'Low-Value']
    pm = validation_df[validation_df['channel_tier'] == 'Premium']
    lv_conv = lv['actual'].mean() if len(lv) > 0 else 0
    pm_conv = pm['actual'].mean() if len(pm) > 0 else 0
    questions.append({
        'Question': 'Are low-value channels underperforming?',
        'Evidence': f'Low-Value: {lv_conv:.1%} (n={len(lv):,}) vs Premium: {pm_conv:.1%}',
        'Verdict': 'Yes — deprioritize' if lv_conv < baseline * 0.5 else 'Monitor'
    })

# Q2: Stale leads
if 'is_stale' in validation_df.columns:
    stale = validation_df[validation_df['is_stale'] == 1]
    fresh = validation_df[validation_df['is_fresh'] == 1]
    s_conv = stale['actual'].mean() if len(stale) > 0 else 0
    f_conv = fresh['actual'].mean() if len(fresh) > 0 else 0
    verdict = 'Still viable' if s_conv > baseline * 0.8 else ('Marginal' if s_conv > baseline * 0.5 else 'Not viable')
    questions.append({
        'Question': 'Do stale leads (>180 days) still convert?',
        'Evidence': f'Stale: {s_conv:.1%} (n={len(stale):,}) vs Fresh: {f_conv:.1%}',
        'Verdict': verdict
    })

# Q3: Hidden gems
if 'is_hidden_gem' in validation_df.columns:
    gems = validation_df[validation_df['is_hidden_gem'] == 1]
    g_conv = gems['actual'].mean() if len(gems) > 0 else 0
    g_lift = g_conv / baseline if baseline > 0 else 0
    verdict = 'Yes — prioritize' if g_conv > baseline * 1.5 else ('Above baseline' if g_conv > baseline else 'Below baseline')
    questions.append({
        'Question': 'Do hidden gem accounts convert at higher rates?',
        'Evidence': f'Gems: {g_conv:.1%} (n={len(gems):,}), Lift: {g_lift:.1f}x',
        'Verdict': verdict
    })

# Q4: Capital density
if 'capital_density_log' in validation_df.columns:
    corr = validation_df['capital_density_log'].corr(validation_df['actual'])
    validation_df['_cq'] = pd.qcut(validation_df['capital_density_log'], 4,
                                    labels=['Q1-Low', 'Q2', 'Q3', 'Q4-High'])
    qconv = validation_df.groupby('_cq')['actual'].mean()
    q1c = qconv.get('Q1-Low', 0)
    q4c = qconv.get('Q4-High', 0)
    verdict = 'Significant' if abs(corr) > 0.1 else ('Weak' if abs(corr) > 0.05 else 'Not predictive')
    questions.append({
        'Question': 'Does capital density correlate with conversion?',
        'Evidence': f'Corr: {corr:.3f}, Q4/Q1 lift: {q4c/q1c:.1f}x' if q1c > 0 else f'Corr: {corr:.3f}',
        'Verdict': verdict
    })
    validation_df.drop(columns=['_cq'], inplace=True)

# Q5: Intent strength
if 'intent_strength' in validation_df.columns:
    corr = validation_df['intent_strength'].corr(validation_df['actual'])
    hi = validation_df[validation_df['intent_strength'] >= 4]['actual'].mean()
    lo = validation_df[validation_df['intent_strength'] <= 1]['actual'].mean()
    lift = hi / lo if lo > 0 else 0
    verdict = 'Strong signal' if corr > 0.1 else ('Weak' if corr > 0.05 else 'Needs revision')
    questions.append({
        'Question': 'Does intent strength predict conversion?',
        'Evidence': f'Corr: {corr:.3f}, High/Low lift: {lift:.1f}x',
        'Verdict': verdict
    })

# Q6: Role-product match
if 'role_product_match' in validation_df.columns:
    matched = validation_df[validation_df['role_product_match'] == 1]
    unmatched = validation_df[validation_df['role_product_match'] == 0]
    m_conv = matched['actual'].mean() if len(matched) > 0 else 0
    u_conv = unmatched['actual'].mean() if len(unmatched) > 0 else 0
    lift = m_conv / u_conv if u_conv > 0 else 0
    verdict = 'Yes — route by match' if m_conv > u_conv * 1.2 else 'Weak impact'
    questions.append({
        'Question': 'Does role-product match increase conversion?',
        'Evidence': f'Matched: {m_conv:.1%} (n={len(matched):,}), Lift: {lift:.1f}x',
        'Verdict': verdict
    })

print_table(pd.DataFrame(questions), caption="Sponsor Q&A — Data Validation")
```

# Conclusion

```{python}
#| label: conclusion

runtime_min = (time.time() - START_TIME) / 60

# Revenue projections
baseline_profit = y_test.sum() * VALUE_PER_SQL - len(y_test) * COST_PER_CALL
annualized_lift = (MAX_PROFIT - baseline_profit) * 12

# Segment analysis
gem_conv = 0
if 'is_hidden_gem' in X_test.columns:
    gm = X_test['is_hidden_gem'] == 1
    gem_conv = y_test[gm.values].mean() if gm.sum() > 0 else 0

lv_conv, lv_n, pm_conv = 0, 0, 0
if 'channel_tier' in df.columns:
    tdf = df.loc[X_test.index].copy()
    tdf['actual'] = y_test
    lv = tdf[tdf['channel_tier'] == 'Low-Value']
    lv_conv, lv_n = (lv['actual'].mean() if len(lv) > 0 else 0), len(lv)
    pm = tdf[tdf['channel_tier'] == 'Premium']
    pm_conv = pm['actual'].mean() if len(pm) > 0 else 0

top_decile = y_test[test_probs >= np.percentile(test_probs, 90)]
golden_rate = top_decile.mean() if len(top_decile) > 0 else 0
```

The analysis identified channel source quality, contact seniority, and industry-weighted budget as the most predictive factors for QAL-to-SQL conversion. The gradient boosting ensemble demonstrated superior performance (AUC {FINAL_AUC:.4f}) compared to individual models.

```{python}
#| label: final-summary

final_summary = pd.DataFrame({
    'Metric': ['Test AUC-ROC', 'Average Precision', 'Best Model',
               'Optimal Threshold', 'Max Profit (Test Set)',
               'Projected Annual Lift', 'Calls Required',
               'SQL Capture Rate', 'Top Decile Conversion',
               'Baseline Conversion', 'Runtime'],
    'Value': [f'{FINAL_AUC:.4f}', f'{test_ap:.4f}', CHAMPION_NAME,
              f'{OPTIMAL_THRESHOLD:.3f}', f'${MAX_PROFIT:,.0f}',
              f'${annualized_lift:,.0f}', f'{int(OPTIMAL_CALLS):,} ({OPTIMAL_PCT_POP:.0%})',
              f'{OPTIMAL_PCT_CAPTURE:.0%}', f'{golden_rate:.1%}',
              f'{y_test.mean():.1%}', f'{runtime_min:.1f} min']
})
print_table(final_summary, caption="Final Model Summary")
```

**Recommended actions:**

1.  **Deploy scoring threshold** of {OPTIMAL_THRESHOLD:.2f} in CRM to prioritize high-probability leads for immediate follow-up.
2.  **Deprioritize low-value channels** (External Demand Gen, Email), which convert at {lv_conv:.1%} across {lv_n:,} leads.
3.  **Route hidden gem accounts** (Non-Manufacturing, "Not Enough Info") to experienced reps — these convert at {gem_conv:.1%}.
4.  **Differentiate P1 urgency** — "Contact Us" P1 leads should route to closers, while "Webinar" P1 leads enter nurture.
5.  **Focus outbound targeting** on Directors/VPs in Pharma & BioTech with Global scope and In-House manufacturing. The top decile converts at {golden_rate:.1%} versus {y_test.mean():.1%} baseline.