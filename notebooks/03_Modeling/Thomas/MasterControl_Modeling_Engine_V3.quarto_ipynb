{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"The Revenue Engine V3: MasterControl Grandmaster Modeling\"\n",
        "subtitle: \"Profit-Optimized Lead Scoring with Calibrated Probabilities\"\n",
        "author: \"MSBA Capstone Group 3\"\n",
        "date: \"Spring 2026\"\n",
        "format:\n",
        "  html:\n",
        "    theme: journal\n",
        "    toc: true\n",
        "    toc-depth: 3\n",
        "    df-print: paged\n",
        "    code-fold: true\n",
        "    code-tools: true\n",
        "  pdf:\n",
        "    documentclass: article\n",
        "    geometry:\n",
        "      - top=1in\n",
        "      - bottom=1in\n",
        "      - left=0.75in\n",
        "      - right=0.75in\n",
        "    toc: true\n",
        "    number-sections: true\n",
        "    colorlinks: true\n",
        "execute:\n",
        "  echo: true\n",
        "  warning: false\n",
        "  message: false\n",
        "editor: visual\n",
        "---\n",
        "\n",
        "# Executive Summary\n",
        "\n",
        "**The Mission:** Push beyond AUC optimization to **Profit Maximization**. V3 introduces three grandmaster upgrades that transform our model from \"good predictions\" to \"optimal business decisions.\"\n",
        "\n",
        "**V3 Upgrades:**\n",
        "\n",
        "1.  **Profit Maximization:** Find the exact probability threshold that maximizes `(SQLs × Value) - (Calls × Cost)`\n",
        "2.  **Probability Calibration:** Ensure predicted probabilities are mathematically accurate, not just ranked\n",
        "3.  **Automated Feature Selection:** Noise reduction via `SelectFromModel` to boost generalization\n",
        "\n",
        "**Key Metrics (V3 vs V2):**\n",
        "\n",
        "| Metric            | V2 Baseline  | V3 Target                |\n",
        "|-------------------|--------------|--------------------------|\n",
        "| Test AUC          | \\~0.86       | 0.87+                    |\n",
        "| Calibration Error | Uncalibrated | \\<5%                     |\n",
        "| Business Metric   | Top-20% Lift | **Max Profit Threshold** |\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "# Phase 1: Production Environment Setup"
      ],
      "id": "8d74424f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: setup\n",
        "\n",
        "# ==============================================================================\n",
        "# PRODUCTION ENVIRONMENT V3 - GRANDMASTER EDITION\n",
        "# ==============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "# Scikit-learn Core\n",
        "import sklearn\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split, cross_val_score, StratifiedKFold,\n",
        "    GridSearchCV, RandomizedSearchCV, cross_val_predict\n",
        ")\n",
        "from sklearn.preprocessing import (\n",
        "    StandardScaler, OneHotEncoder, LabelEncoder,\n",
        "    FunctionTransformer, PolynomialFeatures\n",
        ")\n",
        "\n",
        "# sklearn version compatibility for OneHotEncoder sparse parameter\n",
        "SKLEARN_VERSION = tuple(int(x) for x in sklearn.__version__.split('.')[:2])\n",
        "OHE_SPARSE_PARAM = 'sparse_output' if SKLEARN_VERSION >= (1, 2) else 'sparse'\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# V3 UPGRADE: Feature Selection\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "# Models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestClassifier, VotingClassifier,\n",
        "    GradientBoostingClassifier\n",
        ")\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# XGBoost & LightGBM (graceful import)\n",
        "try:\n",
        "    import xgboost as xgb\n",
        "    XGBOOST_AVAILABLE = True\n",
        "except ImportError:\n",
        "    XGBOOST_AVAILABLE = False\n",
        "    print(\"Warning: XGBoost not available. Install with: pip install xgboost\")\n",
        "\n",
        "try:\n",
        "    import lightgbm as lgb\n",
        "    LIGHTGBM_AVAILABLE = True\n",
        "except ImportError:\n",
        "    LIGHTGBM_AVAILABLE = False\n",
        "    print(\"Warning: LightGBM not available. Install with: pip install lightgbm\")\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, precision_recall_curve, auc,\n",
        "    log_loss, classification_report, confusion_matrix,\n",
        "    roc_curve, precision_score, recall_score, f1_score,\n",
        "    make_scorer, brier_score_loss\n",
        ")\n",
        "\n",
        "# V3 UPGRADE: Calibration\n",
        "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
        "\n",
        "# Interpretability\n",
        "try:\n",
        "    import shap\n",
        "    SHAP_AVAILABLE = True\n",
        "except ImportError:\n",
        "    SHAP_AVAILABLE = False\n",
        "    print(\"Warning: SHAP not available. Install with: pip install shap\")\n",
        "\n",
        "# Parallelization\n",
        "from joblib import Parallel, delayed\n",
        "import multiprocessing\n",
        "\n",
        "# ==============================================================================\n",
        "# PATH CONFIGURATION (Repository Architecture)\n",
        "# ==============================================================================\n",
        "# This script lives at: notebooks/03_Modeling/Thomas/\n",
        "# We need to go up 3 levels to reach repository root\n",
        "\n",
        "REPO_ROOT = Path.cwd().parents[2]  # notebooks/03_Modeling/Thomas -> repo root\n",
        "DATA_DIR = REPO_ROOT / \"data\"\n",
        "OUTPUT_DIR = REPO_ROOT / \"output\"\n",
        "ARTIFACTS_DIR = Path(\"artifacts\")  # Local for plots/model artifacts\n",
        "\n",
        "# Ensure directories exist\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Data file paths\n",
        "RAW_DATA_PATH = DATA_DIR / \"QAL Performance for MSBA.csv\"\n",
        "CLEANED_DATA_PATH = OUTPUT_DIR / \"Cleaned_QAL_Performance_for_MSBA.csv\"\n",
        "\n",
        "# ==============================================================================\n",
        "# GLOBAL CONFIGURATION\n",
        "# ==============================================================================\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "N_JOBS = -1  # Use all cores\n",
        "CV_FOLDS = 5\n",
        "TEST_SIZE = 0.2\n",
        "\n",
        "# ==============================================================================\n",
        "# V3 UPGRADE: BUSINESS ECONOMICS (The Real ROI)\n",
        "# ==============================================================================\n",
        "# Cost-Benefit Parameters for Profit Optimization\n",
        "COST_PER_CALL = 50          # $ cost to contact a lead (SDR time, tools, etc.)\n",
        "AVG_DEAL_SIZE = 50000       # $ average deal value\n",
        "SQL_TO_DEAL_RATE = 0.12     # 12% of SQLs become deals\n",
        "DEAL_CLOSE_RATE = 0.05      # 5% of deals close (conservative)\n",
        "VALUE_PER_SQL = AVG_DEAL_SIZE * SQL_TO_DEAL_RATE  # $6,000 per SQL\n",
        "\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "# Project Colors (The Golden Palette)\n",
        "PROJECT_COLS = {\n",
        "    'Success': '#00534B',   # MasterControl Teal\n",
        "    'Failure': '#F05627',   # Risk Orange\n",
        "    'Neutral': '#95a5a6',   # Gray\n",
        "    'Highlight': '#2980b9', # Blue\n",
        "    'Gold': '#f39c12',      # Accent Gold\n",
        "    'Purple': '#9b59b6',    # Accent Purple\n",
        "    'Profit': '#27ae60'     # Money Green\n",
        "}\n",
        "\n",
        "# Plotting configuration\n",
        "sns.set_theme(style=\"whitegrid\", context=\"talk\")\n",
        "plt.rcParams['figure.figsize'] = (14, 8)\n",
        "plt.rcParams['axes.titleweight'] = 'bold'\n",
        "plt.rcParams['font.family'] = 'sans-serif'\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"PRODUCTION MODELING ENVIRONMENT V3 - GRANDMASTER EDITION\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Repository Root: {REPO_ROOT}\")\n",
        "print(f\"Data Directory: {DATA_DIR}\")\n",
        "print(f\"Output Directory: {OUTPUT_DIR}\")\n",
        "print(f\"Raw Data File: {RAW_DATA_PATH} (exists: {RAW_DATA_PATH.exists()})\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"Random State: {RANDOM_STATE}\")\n",
        "print(f\"CPU Cores: {multiprocessing.cpu_count()}\")\n",
        "print(f\"CV Folds: {CV_FOLDS}\")\n",
        "print(f\"XGBoost: {'Available' if XGBOOST_AVAILABLE else 'Not Available'}\")\n",
        "print(f\"LightGBM: {'Available' if LIGHTGBM_AVAILABLE else 'Not Available'}\")\n",
        "print(f\"SHAP: {'Available' if SHAP_AVAILABLE else 'Not Available'}\")\n",
        "print(\"-\" * 70)\n",
        "print(\"V3 BUSINESS ECONOMICS:\")\n",
        "print(f\"  Cost per Call: ${COST_PER_CALL}\")\n",
        "print(f\"  Value per SQL: ${VALUE_PER_SQL:,.0f}\")\n",
        "print(f\"  Break-even: {COST_PER_CALL / VALUE_PER_SQL:.1%} conversion required\")\n",
        "print(\"=\" * 70)"
      ],
      "id": "setup",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "# Phase 2: Data Loading & Advanced Feature Engineering"
      ],
      "id": "e59905c9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: data-loading\n",
        "\n",
        "# ==============================================================================\n",
        "# DATA LOADING (Using Repository Architecture)\n",
        "# ==============================================================================\n",
        "\n",
        "def load_data():\n",
        "    \"\"\"Load raw data from the configured data directory.\"\"\"\n",
        "    if not RAW_DATA_PATH.exists():\n",
        "        raise FileNotFoundError(f\"❌ CRITICAL: Data file not found at {RAW_DATA_PATH}\")\n",
        "\n",
        "    df = pd.read_csv(RAW_DATA_PATH)\n",
        "    print(f\"✓ Data loaded from: {RAW_DATA_PATH}\")\n",
        "    return df\n",
        "\n",
        "df_raw = load_data()\n",
        "\n",
        "# Standardize column names\n",
        "df_raw.columns = [c.strip().lower().replace(' ', '_').replace('/', '_').replace('-', '_')\n",
        "                  for c in df_raw.columns]\n",
        "\n",
        "print(f\"Raw Data Shape: {df_raw.shape}\")"
      ],
      "id": "data-loading",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: feature-engineering\n",
        "\n",
        "# ==============================================================================\n",
        "# ADVANCED FEATURE ENGINEERING PIPELINE\n",
        "# ==============================================================================\n",
        "\n",
        "def engineer_features(df):\n",
        "    \"\"\"\n",
        "    V3 Feature Engineering with Advanced Techniques.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 1. TARGET VARIABLE\n",
        "    # -------------------------------------------------------------------------\n",
        "    success_stages = ['SQL', 'SQO', 'Won']\n",
        "    df['is_success'] = df['next_stage__c'].isin(success_stages).astype(int)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 2. PRODUCT SEGMENTATION\n",
        "    # -------------------------------------------------------------------------\n",
        "    def segment_product(sol):\n",
        "        if str(sol) == 'Mx': return 'Mx'\n",
        "        elif str(sol) == 'Qx': return 'Qx'\n",
        "        return 'Other'\n",
        "    df['product_segment'] = df['solution_rollup'].apply(segment_product)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 3. TITLE PARSING (Enhanced)\n",
        "    # -------------------------------------------------------------------------\n",
        "    def parse_seniority(t):\n",
        "        if pd.isna(t): return 'Unknown'\n",
        "        t = str(t).lower()\n",
        "        if re.search(r'\\b(ceo|cfo|coo|cto|cio|chief|c-level|president|founder|owner)\\b', t):\n",
        "            return 'C-Suite'\n",
        "        if re.search(r'\\b(svp|senior vice president|evp)\\b', t):\n",
        "            return 'SVP'\n",
        "        if re.search(r'\\b(vp|vice president|head of)\\b', t):\n",
        "            return 'VP'\n",
        "        if re.search(r'\\b(director)\\b', t):\n",
        "            return 'Director'\n",
        "        if re.search(r'\\b(manager|mgr|lead|supervisor)\\b', t):\n",
        "            return 'Manager'\n",
        "        if re.search(r'\\b(analyst|engineer|specialist|associate|coordinator)\\b', t):\n",
        "            return 'IC'\n",
        "        return 'Other'\n",
        "\n",
        "    def parse_function(t):\n",
        "        if pd.isna(t): return 'Unknown'\n",
        "        t = str(t).lower()\n",
        "        if re.search(r'\\b(manuf|prod|ops|plant|supply|site|factory)\\b', t):\n",
        "            return 'Manufacturing_Ops'\n",
        "        if re.search(r'\\b(quality|qa|qc|qms|compliance|validation|capa)\\b', t):\n",
        "            return 'Quality_Reg'\n",
        "        if re.search(r'\\b(regulatory|reg affairs|submissions)\\b', t):\n",
        "            return 'Regulatory'\n",
        "        if re.search(r'\\b(it|info|sys|tech|data|soft)\\b', t):\n",
        "            return 'IT_Systems'\n",
        "        if re.search(r'\\b(lab|r&d|sci|dev|clin|research)\\b', t):\n",
        "            return 'R_D_Lab'\n",
        "        return 'Other'\n",
        "\n",
        "    def parse_scope(t):\n",
        "        if pd.isna(t): return 'Standard'\n",
        "        t = str(t).lower()\n",
        "        if re.search(r'\\b(global|worldwide|international|corporate|enterprise|group)\\b', t):\n",
        "            return 'Global'\n",
        "        if re.search(r'\\b(regional|division)\\b', t):\n",
        "            return 'Regional'\n",
        "        if re.search(r'\\b(site|plant|facility|local)\\b', t):\n",
        "            return 'Site'\n",
        "        return 'Standard'\n",
        "\n",
        "    df['title_seniority'] = df['contact_lead_title'].apply(parse_seniority)\n",
        "    df['title_function'] = df['contact_lead_title'].apply(parse_function)\n",
        "    df['title_scope'] = df['contact_lead_title'].apply(parse_scope)\n",
        "    df['is_decision_maker'] = df['title_seniority'].isin(\n",
        "        ['C-Suite', 'SVP', 'VP', 'Director']\n",
        "    ).astype(int)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 4. RECORD COMPLETENESS\n",
        "    # -------------------------------------------------------------------------\n",
        "    completeness_cols = [\n",
        "        'acct_manufacturing_model', 'acct_primary_site_function',\n",
        "        'acct_target_industry', 'acct_territory_rollup', 'acct_tier_rollup'\n",
        "    ]\n",
        "\n",
        "    def calc_completeness(row):\n",
        "        filled = sum(1 for col in completeness_cols\n",
        "                     if col in row.index and pd.notna(row[col])\n",
        "                     and str(row[col]).lower() not in ['unknown', 'nan', ''])\n",
        "        return filled / len(completeness_cols)\n",
        "\n",
        "    df['record_completeness'] = df.apply(calc_completeness, axis=1)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 5. TEMPORAL FEATURES\n",
        "    # -------------------------------------------------------------------------\n",
        "    df['cohort_date'] = pd.to_datetime(df['qal_cohort_date'], errors='coerce')\n",
        "    df['cohort_quarter'] = df['cohort_date'].dt.quarter.fillna(0).astype(int)\n",
        "    df['cohort_month'] = df['cohort_date'].dt.month.fillna(0).astype(int)\n",
        "    df['cohort_dayofweek'] = df['cohort_date'].dt.dayofweek.fillna(0).astype(int)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 6. IMPUTATION\n",
        "    # -------------------------------------------------------------------------\n",
        "    fill_cols = ['acct_target_industry', 'acct_manufacturing_model',\n",
        "                 'acct_territory_rollup', 'acct_primary_site_function']\n",
        "    for col in fill_cols:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].fillna('Unknown')\n",
        "\n",
        "    df['contact_lead_title'] = df['contact_lead_title'].fillna('Unknown Title')\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 7. HIGH-VALUE INTERACTION: Seniority x Function (Explicit)\n",
        "    # -------------------------------------------------------------------------\n",
        "    df['seniority_function'] = df['title_seniority'] + '_X_' + df['title_function']\n",
        "\n",
        "    return df\n",
        "\n",
        "# Apply feature engineering\n",
        "df = engineer_features(df_raw)\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"FEATURE ENGINEERING COMPLETE\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Total Records: {len(df):,}\")\n",
        "print(f\"Target Rate: {df['is_success'].mean():.1%}\")\n",
        "print(f\"Mx Leads: {len(df[df['product_segment']=='Mx']):,}\")\n",
        "print(f\"Unique Industries: {df['acct_target_industry'].nunique()}\")\n",
        "print(f\"Unique Seniority x Function: {df['seniority_function'].nunique()}\")"
      ],
      "id": "feature-engineering",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "# Phase 3: Custom Transformers"
      ],
      "id": "1d95cb36"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: custom-transformers\n",
        "\n",
        "# ==============================================================================\n",
        "# CUSTOM TARGET ENCODER (Smoothed)\n",
        "# ==============================================================================\n",
        "\n",
        "class TargetEncoder(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Smoothed Target Encoding for high-cardinality categorical features.\n",
        "    Uses leave-one-out encoding to prevent target leakage.\n",
        "\n",
        "    Formula: encoded = (count * mean + global_mean * smoothing) / (count + smoothing)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, smoothing=10, min_samples=5):\n",
        "        self.smoothing = smoothing\n",
        "        self.min_samples = min_samples\n",
        "        self.encoding_map_ = {}\n",
        "        self.global_mean_ = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X = np.array(X).ravel()\n",
        "        y = np.array(y).ravel()\n",
        "\n",
        "        self.global_mean_ = y.mean()\n",
        "\n",
        "        df = pd.DataFrame({'feature': X, 'target': y})\n",
        "        agg = df.groupby('feature')['target'].agg(['mean', 'count'])\n",
        "\n",
        "        # Smoothed encoding\n",
        "        smoothed_mean = (\n",
        "            (agg['count'] * agg['mean'] + self.smoothing * self.global_mean_) /\n",
        "            (agg['count'] + self.smoothing)\n",
        "        )\n",
        "\n",
        "        # Replace low-count categories with global mean\n",
        "        smoothed_mean[agg['count'] < self.min_samples] = self.global_mean_\n",
        "\n",
        "        self.encoding_map_ = smoothed_mean.to_dict()\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = np.array(X).ravel()\n",
        "        encoded = np.array([\n",
        "            self.encoding_map_.get(val, self.global_mean_)\n",
        "            for val in X\n",
        "        ]).reshape(-1, 1)\n",
        "        return encoded\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# LSA TEXT TRANSFORMER\n",
        "# ==============================================================================\n",
        "\n",
        "class LSATextTransformer(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Latent Semantic Analysis for text features.\n",
        "    TF-IDF -> TruncatedSVD -> Dense semantic components.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_components=15, max_features=500):\n",
        "        self.n_components = n_components\n",
        "        self.max_features = max_features\n",
        "        self.tfidf = None\n",
        "        self.svd = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        X = np.array(X).ravel()\n",
        "        X = [str(x).lower() if pd.notna(x) else 'unknown' for x in X]\n",
        "\n",
        "        self.tfidf = TfidfVectorizer(\n",
        "            max_features=self.max_features,\n",
        "            stop_words='english',\n",
        "            ngram_range=(1, 2),\n",
        "            min_df=5,\n",
        "            max_df=0.95\n",
        "        )\n",
        "\n",
        "        tfidf_matrix = self.tfidf.fit_transform(X)\n",
        "\n",
        "        # LSA via TruncatedSVD\n",
        "        n_comp = min(self.n_components, tfidf_matrix.shape[1] - 1)\n",
        "        self.svd = TruncatedSVD(n_components=n_comp, random_state=RANDOM_STATE)\n",
        "        self.svd.fit(tfidf_matrix)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = np.array(X).ravel()\n",
        "        X = [str(x).lower() if pd.notna(x) else 'unknown' for x in X]\n",
        "\n",
        "        tfidf_matrix = self.tfidf.transform(X)\n",
        "        lsa_matrix = self.svd.transform(tfidf_matrix)\n",
        "\n",
        "        return lsa_matrix\n",
        "\n",
        "    def get_feature_names_out(self, input_features=None):\n",
        "        return np.array([f'LSA_{i}' for i in range(self.svd.n_components)])\n",
        "\n",
        "\n",
        "print(\"Custom Transformers Defined: TargetEncoder, LSATextTransformer\")"
      ],
      "id": "custom-transformers",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "# Phase 4: Model-Ready Dataset"
      ],
      "id": "0eb84573"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: model-prep\n",
        "\n",
        "# ==============================================================================\n",
        "# PREPARE MX-FOCUSED DATASET\n",
        "# ==============================================================================\n",
        "\n",
        "# Filter to Mx leads only\n",
        "df_mx = df[df['product_segment'] == 'Mx'].copy()\n",
        "\n",
        "print(f\"Mx Dataset: {len(df_mx):,} leads\")\n",
        "print(f\"Mx Conversion Rate: {df_mx['is_success'].mean():.1%}\")\n",
        "\n",
        "# Define feature groups\n",
        "CATEGORICAL_LOW_CARD = [\n",
        "    'title_seniority',\n",
        "    'title_function',\n",
        "    'title_scope',\n",
        "    'acct_manufacturing_model',\n",
        "    'acct_territory_rollup'\n",
        "]\n",
        "\n",
        "CATEGORICAL_HIGH_CARD = [\n",
        "    'acct_target_industry'  # Target encode this\n",
        "]\n",
        "\n",
        "INTERACTION_FEATURES = [\n",
        "    'seniority_function'  # Pre-computed interaction\n",
        "]\n",
        "\n",
        "NUMERIC_FEATURES = [\n",
        "    'is_decision_maker',\n",
        "    'record_completeness',\n",
        "    'cohort_quarter',\n",
        "    'cohort_month',\n",
        "    'cohort_dayofweek'\n",
        "]\n",
        "\n",
        "TEXT_FEATURE = 'contact_lead_title'\n",
        "TARGET = 'is_success'\n",
        "\n",
        "# Filter to existing columns\n",
        "CATEGORICAL_LOW_CARD = [f for f in CATEGORICAL_LOW_CARD if f in df_mx.columns]\n",
        "CATEGORICAL_HIGH_CARD = [f for f in CATEGORICAL_HIGH_CARD if f in df_mx.columns]\n",
        "INTERACTION_FEATURES = [f for f in INTERACTION_FEATURES if f in df_mx.columns]\n",
        "NUMERIC_FEATURES = [f for f in NUMERIC_FEATURES if f in df_mx.columns]\n",
        "\n",
        "ALL_FEATURES = CATEGORICAL_LOW_CARD + CATEGORICAL_HIGH_CARD + INTERACTION_FEATURES + NUMERIC_FEATURES + [TEXT_FEATURE]\n",
        "\n",
        "print(f\"\\nLow-Card Categorical: {CATEGORICAL_LOW_CARD}\")\n",
        "print(f\"High-Card (Target Encode): {CATEGORICAL_HIGH_CARD}\")\n",
        "print(f\"Interaction Features: {INTERACTION_FEATURES}\")\n",
        "print(f\"Numeric: {NUMERIC_FEATURES}\")\n",
        "print(f\"Text (LSA): {TEXT_FEATURE}\")"
      ],
      "id": "model-prep",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: train-test-split\n",
        "\n",
        "# ==============================================================================\n",
        "# STRATIFIED TRAIN/VALIDATION/TEST SPLIT (V3: 3-way split for calibration)\n",
        "# ==============================================================================\n",
        "\n",
        "X = df_mx[ALL_FEATURES].copy()\n",
        "y = df_mx[TARGET].copy()\n",
        "\n",
        "# First split: Train+Val vs Test\n",
        "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=TEST_SIZE,\n",
        "    random_state=RANDOM_STATE,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# Second split: Train vs Validation (for calibration)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_trainval, y_trainval,\n",
        "    test_size=0.15,  # 15% of trainval for calibration\n",
        "    random_state=RANDOM_STATE,\n",
        "    stratify=y_trainval\n",
        ")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"TRAIN/VALIDATION/TEST SPLIT (V3: 3-Way for Calibration)\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Training: {len(X_train):,} ({len(X_train)/len(X):.0%})\")\n",
        "print(f\"Validation (Calibration): {len(X_val):,} ({len(X_val)/len(X):.0%})\")\n",
        "print(f\"Test: {len(X_test):,} ({len(X_test)/len(X):.0%})\")\n",
        "print(f\"Train Target Rate: {y_train.mean():.1%}\")\n",
        "print(f\"Val Target Rate: {y_val.mean():.1%}\")\n",
        "print(f\"Test Target Rate: {y_test.mean():.1%}\")"
      ],
      "id": "train-test-split",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "# Phase 5: Advanced Preprocessing Pipeline"
      ],
      "id": "3729ce39"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: preprocessing\n",
        "\n",
        "# ==============================================================================\n",
        "# ADVANCED PREPROCESSING PIPELINE\n",
        "# ==============================================================================\n",
        "\n",
        "# 1. Numeric Pipeline\n",
        "numeric_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# 2. Low-Cardinality Categorical Pipeline (OneHot)\n",
        "categorical_low_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', **{OHE_SPARSE_PARAM: False}))\n",
        "])\n",
        "\n",
        "# 3. Interaction Features Pipeline (OneHot with limit)\n",
        "interaction_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', max_categories=30,\n",
        "                             **{OHE_SPARSE_PARAM: False}))\n",
        "])\n",
        "\n",
        "# 4. LSA Text Pipeline\n",
        "lsa_pipeline = LSATextTransformer(n_components=15, max_features=500)\n",
        "\n",
        "# Build ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_pipeline, NUMERIC_FEATURES),\n",
        "        ('cat_low', categorical_low_pipeline, CATEGORICAL_LOW_CARD),\n",
        "        ('interaction', interaction_pipeline, INTERACTION_FEATURES),\n",
        "        ('lsa', lsa_pipeline, TEXT_FEATURE)\n",
        "    ],\n",
        "    remainder='drop',\n",
        "    n_jobs=N_JOBS\n",
        ")\n",
        "\n",
        "# Fit preprocessor on training data only\n",
        "X_train_base = preprocessor.fit_transform(X_train)\n",
        "X_val_base = preprocessor.transform(X_val)\n",
        "X_test_base = preprocessor.transform(X_test)\n",
        "\n",
        "print(f\"Base Features Shape: {X_train_base.shape}\")\n",
        "\n",
        "# Add Target Encoding for high-cardinality features\n",
        "if CATEGORICAL_HIGH_CARD:\n",
        "    target_encoders = {}\n",
        "    target_encoded_train = []\n",
        "    target_encoded_val = []\n",
        "    target_encoded_test = []\n",
        "\n",
        "    for col in CATEGORICAL_HIGH_CARD:\n",
        "        te = TargetEncoder(smoothing=10, min_samples=5)\n",
        "        te.fit(X_train[col], y_train)\n",
        "        target_encoders[col] = te\n",
        "\n",
        "        target_encoded_train.append(te.transform(X_train[col]))\n",
        "        target_encoded_val.append(te.transform(X_val[col]))\n",
        "        target_encoded_test.append(te.transform(X_test[col]))\n",
        "\n",
        "    target_train = np.hstack(target_encoded_train)\n",
        "    target_val = np.hstack(target_encoded_val)\n",
        "    target_test = np.hstack(target_encoded_test)\n",
        "\n",
        "    X_train_processed = np.hstack([X_train_base, target_train])\n",
        "    X_val_processed = np.hstack([X_val_base, target_val])\n",
        "    X_test_processed = np.hstack([X_test_base, target_test])\n",
        "\n",
        "    print(f\"+ Target Encoded: {target_train.shape[1]} features\")\n",
        "else:\n",
        "    X_train_processed = X_train_base\n",
        "    X_val_processed = X_val_base\n",
        "    X_test_processed = X_test_base\n",
        "\n",
        "print(f\"Final Features Shape: {X_train_processed.shape}\")"
      ],
      "id": "preprocessing",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: feature-selection\n",
        "\n",
        "# ==============================================================================\n",
        "# V3 UPGRADE: AUTOMATED FEATURE SELECTION (Noise Reduction)\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"V3 UPGRADE: AUTOMATED FEATURE SELECTION\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Use a quick Random Forest to identify zero-importance features\n",
        "selector_rf = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    min_samples_leaf=20,\n",
        "    random_state=RANDOM_STATE,\n",
        "    n_jobs=N_JOBS\n",
        ")\n",
        "\n",
        "# Fit selector\n",
        "selector = SelectFromModel(selector_rf, threshold='mean', prefit=False)\n",
        "selector.fit(X_train_processed, y_train)\n",
        "\n",
        "# Get selected feature mask\n",
        "selected_mask = selector.get_support()\n",
        "n_selected = selected_mask.sum()\n",
        "n_dropped = len(selected_mask) - n_selected\n",
        "\n",
        "print(f\"Original Features: {len(selected_mask)}\")\n",
        "print(f\"Selected Features: {n_selected} ({n_selected/len(selected_mask):.0%})\")\n",
        "print(f\"Dropped Features: {n_dropped} (below mean importance)\")\n",
        "\n",
        "# Apply selection\n",
        "X_train_selected = selector.transform(X_train_processed)\n",
        "X_val_selected = selector.transform(X_val_processed)\n",
        "X_test_selected = selector.transform(X_test_processed)\n",
        "\n",
        "print(f\"\\nFinal Training Shape: {X_train_selected.shape}\")\n",
        "\n",
        "# Get feature names (approximate)\n",
        "def get_feature_names():\n",
        "    names = []\n",
        "    names.extend([f'num_{c}' for c in NUMERIC_FEATURES])\n",
        "\n",
        "    try:\n",
        "        ohe = preprocessor.named_transformers_['cat_low'].named_steps['onehot']\n",
        "        names.extend(ohe.get_feature_names_out(CATEGORICAL_LOW_CARD))\n",
        "    except:\n",
        "        names.extend([f'cat_{c}' for c in CATEGORICAL_LOW_CARD])\n",
        "\n",
        "    try:\n",
        "        ohe = preprocessor.named_transformers_['interaction'].named_steps['onehot']\n",
        "        names.extend(ohe.get_feature_names_out(INTERACTION_FEATURES))\n",
        "    except:\n",
        "        names.extend([f'int_{c}' for c in INTERACTION_FEATURES])\n",
        "\n",
        "    names.extend([f'LSA_{i}' for i in range(15)])\n",
        "    names.extend([f'TE_{c}' for c in CATEGORICAL_HIGH_CARD])\n",
        "\n",
        "    return names\n",
        "\n",
        "FEATURE_NAMES = get_feature_names()\n",
        "SELECTED_FEATURE_NAMES = [FEATURE_NAMES[i] for i in range(len(FEATURE_NAMES))\n",
        "                          if i < len(selected_mask) and selected_mask[i]]\n",
        "\n",
        "print(f\"Feature Names Count: {len(SELECTED_FEATURE_NAMES)}\")"
      ],
      "id": "feature-selection",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "# Phase 6: The Super-Model Tournament"
      ],
      "id": "5699307a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: model-definitions\n",
        "\n",
        "# ==============================================================================\n",
        "# MODEL DEFINITIONS WITH HYPERPARAMETER GRIDS\n",
        "# ==============================================================================\n",
        "\n",
        "# Calculate class weight for imbalanced data\n",
        "pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
        "print(f\"Class Imbalance Ratio: {pos_weight:.2f}:1\")\n",
        "\n",
        "# Base models\n",
        "models = {}\n",
        "\n",
        "# 1. LOGISTIC REGRESSION (LASSO)\n",
        "models['Logistic_LASSO'] = {\n",
        "    'model': LogisticRegression(\n",
        "        penalty='l1',\n",
        "        solver='saga',\n",
        "        max_iter=1000,\n",
        "        random_state=RANDOM_STATE,\n",
        "        n_jobs=N_JOBS,\n",
        "        class_weight='balanced'\n",
        "    ),\n",
        "    'params': {\n",
        "        'C': [0.01, 0.1, 1.0]\n",
        "    }\n",
        "}\n",
        "\n",
        "# 2. RANDOM FOREST\n",
        "models['Random_Forest'] = {\n",
        "    'model': RandomForestClassifier(\n",
        "        random_state=RANDOM_STATE,\n",
        "        n_jobs=N_JOBS,\n",
        "        class_weight='balanced'\n",
        "    ),\n",
        "    'params': {\n",
        "        'n_estimators': [100, 200],\n",
        "        'max_depth': [8, 12],\n",
        "        'min_samples_leaf': [10, 20]\n",
        "    }\n",
        "}\n",
        "\n",
        "# 3. XGBOOST (Tuned)\n",
        "if XGBOOST_AVAILABLE:\n",
        "    models['XGBoost'] = {\n",
        "        'model': xgb.XGBClassifier(\n",
        "            random_state=RANDOM_STATE,\n",
        "            n_jobs=N_JOBS,\n",
        "            eval_metric='logloss'\n",
        "        ),\n",
        "        'params': {\n",
        "            'n_estimators': [150, 250],\n",
        "            'max_depth': [4, 6, 8],\n",
        "            'learning_rate': [0.05, 0.1],\n",
        "            'scale_pos_weight': [1, pos_weight],\n",
        "            'subsample': [0.8],\n",
        "            'colsample_bytree': [0.8]\n",
        "        }\n",
        "    }\n",
        "\n",
        "# 4. LIGHTGBM (Fast & Powerful)\n",
        "if LIGHTGBM_AVAILABLE:\n",
        "    models['LightGBM'] = {\n",
        "        'model': lgb.LGBMClassifier(\n",
        "            random_state=RANDOM_STATE,\n",
        "            n_jobs=N_JOBS,\n",
        "            verbose=-1\n",
        "        ),\n",
        "        'params': {\n",
        "            'n_estimators': [150, 250],\n",
        "            'max_depth': [4, 6, 8],\n",
        "            'learning_rate': [0.05, 0.1],\n",
        "            'scale_pos_weight': [1, pos_weight],\n",
        "            'num_leaves': [31, 63]\n",
        "        }\n",
        "    }\n",
        "\n",
        "# 5. GRADIENT BOOSTING (sklearn native)\n",
        "models['GradientBoosting'] = {\n",
        "    'model': GradientBoostingClassifier(\n",
        "        random_state=RANDOM_STATE\n",
        "    ),\n",
        "    'params': {\n",
        "        'n_estimators': [100, 150],\n",
        "        'max_depth': [4, 6],\n",
        "        'learning_rate': [0.05, 0.1],\n",
        "        'subsample': [0.8]\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"SUPER-MODEL TOURNAMENT\")\n",
        "print(\"=\" * 70)\n",
        "for name in models:\n",
        "    print(f\"  - {name}\")"
      ],
      "id": "model-definitions",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: model-training\n",
        "\n",
        "# ==============================================================================\n",
        "# HYPERPARAMETER TUNING & TRAINING\n",
        "# ==============================================================================\n",
        "\n",
        "cv = StratifiedKFold(n_splits=CV_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
        "\n",
        "results = {}\n",
        "best_estimators = {}\n",
        "\n",
        "print(f\"\\nTraining with {CV_FOLDS}-fold CV + GridSearchCV...\\n\")\n",
        "\n",
        "for name, config in models.items():\n",
        "    print(f\"Training {name}...\", end=\" \")\n",
        "    start_time = datetime.now()\n",
        "\n",
        "    # GridSearchCV\n",
        "    grid = GridSearchCV(\n",
        "        config['model'],\n",
        "        config['params'],\n",
        "        cv=cv,\n",
        "        scoring='roc_auc',\n",
        "        n_jobs=N_JOBS,\n",
        "        refit=True\n",
        "    )\n",
        "\n",
        "    grid.fit(X_train_selected, y_train)\n",
        "\n",
        "    best_model = grid.best_estimator_\n",
        "    best_estimators[name] = best_model\n",
        "\n",
        "    # Validation predictions (for calibration later)\n",
        "    val_probs = best_model.predict_proba(X_val_selected)[:, 1]\n",
        "\n",
        "    # Test predictions\n",
        "    test_probs = best_model.predict_proba(X_test_selected)[:, 1]\n",
        "    test_preds = best_model.predict(X_test_selected)\n",
        "\n",
        "    # Metrics\n",
        "    test_auc = roc_auc_score(y_test, test_probs)\n",
        "    test_logloss = log_loss(y_test, test_probs)\n",
        "    precision, recall, _ = precision_recall_curve(y_test, test_probs)\n",
        "    pr_auc = auc(recall, precision)\n",
        "    brier = brier_score_loss(y_test, test_probs)\n",
        "\n",
        "    elapsed = (datetime.now() - start_time).total_seconds()\n",
        "\n",
        "    results[name] = {\n",
        "        'model': best_model,\n",
        "        'best_params': grid.best_params_,\n",
        "        'cv_auc': grid.best_score_,\n",
        "        'test_auc': test_auc,\n",
        "        'test_logloss': test_logloss,\n",
        "        'pr_auc': pr_auc,\n",
        "        'brier_score': brier,\n",
        "        'test_probs': test_probs,\n",
        "        'val_probs': val_probs,\n",
        "        'test_preds': test_preds,\n",
        "        'train_time': elapsed\n",
        "    }\n",
        "\n",
        "    print(f\"AUC={test_auc:.4f}, Brier={brier:.4f} (Time: {elapsed:.1f}s)\")\n",
        "\n",
        "print(\"\\nAll base models trained!\")"
      ],
      "id": "model-training",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: voting-ensemble\n",
        "\n",
        "# ==============================================================================\n",
        "# VOTING ENSEMBLE (THE CLOSER)\n",
        "# ==============================================================================\n",
        "\n",
        "# Select top 3 models by test AUC\n",
        "sorted_models = sorted(results.items(), key=lambda x: x[1]['test_auc'], reverse=True)\n",
        "top_3 = sorted_models[:3]\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"VOTING ENSEMBLE: Combining Top 3 Models\")\n",
        "print(\"=\" * 70)\n",
        "for name, r in top_3:\n",
        "    print(f\"  - {name}: AUC={r['test_auc']:.4f}\")\n",
        "\n",
        "# Create voting classifier\n",
        "voting_estimators = [(name, best_estimators[name]) for name, _ in top_3]\n",
        "\n",
        "ensemble = VotingClassifier(\n",
        "    estimators=voting_estimators,\n",
        "    voting='soft',\n",
        "    n_jobs=N_JOBS\n",
        ")\n",
        "\n",
        "print(\"\\nTraining Voting Ensemble...\")\n",
        "start_time = datetime.now()\n",
        "ensemble.fit(X_train_selected, y_train)\n",
        "\n",
        "# Ensemble predictions\n",
        "ensemble_val_probs = ensemble.predict_proba(X_val_selected)[:, 1]\n",
        "ensemble_test_probs = ensemble.predict_proba(X_test_selected)[:, 1]\n",
        "ensemble_test_preds = ensemble.predict(X_test_selected)\n",
        "\n",
        "# Metrics\n",
        "ensemble_auc = roc_auc_score(y_test, ensemble_test_probs)\n",
        "ensemble_logloss = log_loss(y_test, ensemble_test_probs)\n",
        "precision, recall, _ = precision_recall_curve(y_test, ensemble_test_probs)\n",
        "ensemble_pr_auc = auc(recall, precision)\n",
        "ensemble_brier = brier_score_loss(y_test, ensemble_test_probs)\n",
        "\n",
        "elapsed = (datetime.now() - start_time).total_seconds()\n",
        "\n",
        "results['Voting_Ensemble'] = {\n",
        "    'model': ensemble,\n",
        "    'best_params': 'N/A (Ensemble)',\n",
        "    'cv_auc': np.mean([results[name]['cv_auc'] for name, _ in top_3]),\n",
        "    'test_auc': ensemble_auc,\n",
        "    'test_logloss': ensemble_logloss,\n",
        "    'pr_auc': ensemble_pr_auc,\n",
        "    'brier_score': ensemble_brier,\n",
        "    'test_probs': ensemble_test_probs,\n",
        "    'val_probs': ensemble_val_probs,\n",
        "    'test_preds': ensemble_test_preds,\n",
        "    'train_time': elapsed\n",
        "}\n",
        "\n",
        "print(f\"Voting Ensemble AUC: {ensemble_auc:.4f}, Brier: {ensemble_brier:.4f}\")"
      ],
      "id": "voting-ensemble",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "# Phase 7: V3 UPGRADE - Probability Calibration"
      ],
      "id": "43739f5e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: calibration\n",
        "\n",
        "# ==============================================================================\n",
        "# V3 UPGRADE: PROBABILITY CALIBRATION\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"V3 UPGRADE: PROBABILITY CALIBRATION\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Calibrate the Voting Ensemble using the validation set\n",
        "print(\"\\nCalibrating Voting Ensemble with isotonic regression...\")\n",
        "\n",
        "calibrated_ensemble = CalibratedClassifierCV(\n",
        "    ensemble,\n",
        "    method='isotonic',  # More flexible than sigmoid\n",
        "    cv='prefit'  # Use prefit since ensemble is already trained\n",
        ")\n",
        "\n",
        "# Fit calibration on validation set\n",
        "calibrated_ensemble.fit(X_val_selected, y_val)\n",
        "\n",
        "# Get calibrated predictions on test set\n",
        "calibrated_probs = calibrated_ensemble.predict_proba(X_test_selected)[:, 1]\n",
        "calibrated_preds = (calibrated_probs >= 0.5).astype(int)\n",
        "\n",
        "# Calculate calibration metrics\n",
        "calibrated_auc = roc_auc_score(y_test, calibrated_probs)\n",
        "calibrated_brier = brier_score_loss(y_test, calibrated_probs)\n",
        "calibrated_logloss = log_loss(y_test, calibrated_probs)\n",
        "\n",
        "print(f\"\\nCALIBRATION RESULTS:\")\n",
        "print(f\"  Uncalibrated AUC:    {ensemble_auc:.4f}\")\n",
        "print(f\"  Calibrated AUC:      {calibrated_auc:.4f}\")\n",
        "print(f\"  Uncalibrated Brier:  {ensemble_brier:.4f}\")\n",
        "print(f\"  Calibrated Brier:    {calibrated_brier:.4f} ({'Improved!' if calibrated_brier < ensemble_brier else 'Same'})\")\n",
        "\n",
        "# Store calibrated results\n",
        "results['Calibrated_Ensemble'] = {\n",
        "    'model': calibrated_ensemble,\n",
        "    'best_params': 'Calibrated (isotonic)',\n",
        "    'cv_auc': results['Voting_Ensemble']['cv_auc'],\n",
        "    'test_auc': calibrated_auc,\n",
        "    'test_logloss': calibrated_logloss,\n",
        "    'pr_auc': results['Voting_Ensemble']['pr_auc'],\n",
        "    'brier_score': calibrated_brier,\n",
        "    'test_probs': calibrated_probs,\n",
        "    'test_preds': calibrated_preds,\n",
        "    'train_time': results['Voting_Ensemble']['train_time']\n",
        "}"
      ],
      "id": "calibration",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: calibration-plot\n",
        "#| fig-cap: 'Calibration Curve: Comparing uncalibrated vs calibrated probabilities.'\n",
        "\n",
        "# ==============================================================================\n",
        "# CALIBRATION VISUALIZATION\n",
        "# ==============================================================================\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# LEFT: Calibration curves\n",
        "ax1 = axes[0]\n",
        "\n",
        "# Uncalibrated\n",
        "prob_true_uncal, prob_pred_uncal = calibration_curve(\n",
        "    y_test, ensemble_test_probs, n_bins=10, strategy='uniform'\n",
        ")\n",
        "\n",
        "# Calibrated\n",
        "prob_true_cal, prob_pred_cal = calibration_curve(\n",
        "    y_test, calibrated_probs, n_bins=10, strategy='uniform'\n",
        ")\n",
        "\n",
        "ax1.plot([0, 1], [0, 1], 'k--', label='Perfectly Calibrated')\n",
        "ax1.plot(prob_pred_uncal, prob_true_uncal, 'o-',\n",
        "         color=PROJECT_COLS['Failure'], label=f'Uncalibrated (Brier={ensemble_brier:.4f})')\n",
        "ax1.plot(prob_pred_cal, prob_true_cal, 's-',\n",
        "         color=PROJECT_COLS['Success'], label=f'Calibrated (Brier={calibrated_brier:.4f})')\n",
        "\n",
        "ax1.set_xlabel('Mean Predicted Probability')\n",
        "ax1.set_ylabel('Fraction of Positives')\n",
        "ax1.set_title('Calibration Curve: Model Reliability', fontweight='bold')\n",
        "ax1.legend(loc='upper left')\n",
        "ax1.grid(alpha=0.3)\n",
        "\n",
        "# RIGHT: Probability distribution\n",
        "ax2 = axes[1]\n",
        "\n",
        "ax2.hist(ensemble_test_probs, bins=30, alpha=0.5, label='Uncalibrated',\n",
        "         color=PROJECT_COLS['Failure'], density=True)\n",
        "ax2.hist(calibrated_probs, bins=30, alpha=0.5, label='Calibrated',\n",
        "         color=PROJECT_COLS['Success'], density=True)\n",
        "\n",
        "ax2.axvline(x=y_test.mean(), color='black', linestyle='--',\n",
        "            label=f'True Rate: {y_test.mean():.1%}')\n",
        "ax2.set_xlabel('Predicted Probability')\n",
        "ax2.set_ylabel('Density')\n",
        "ax2.set_title('Probability Distribution Shift', fontweight='bold')\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nCalibration improves probability estimates without changing rankings (AUC).\")\n",
        "print(\"This ensures our revenue projections are mathematically accurate.\")"
      ],
      "id": "calibration-plot",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "# Phase 8: V3 UPGRADE - Profit Maximization"
      ],
      "id": "21afc02d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: profit-optimization\n",
        "\n",
        "# ==============================================================================\n",
        "# V3 UPGRADE: PROFIT MAXIMIZATION\n",
        "# ==============================================================================\n",
        "\n",
        "def calculate_profit_curve(y_true, y_pred_proba, cost_per_call=COST_PER_CALL,\n",
        "                           value_per_sql=VALUE_PER_SQL):\n",
        "    \"\"\"\n",
        "    Calculate profit at each threshold.\n",
        "\n",
        "    Profit = (SQLs Captured * Value) - (Leads Called * Cost)\n",
        "    \"\"\"\n",
        "    thresholds = np.linspace(0.01, 0.99, 99)\n",
        "    profits = []\n",
        "    metrics = []\n",
        "\n",
        "    for thresh in thresholds:\n",
        "        # Leads we would call (predicted positive)\n",
        "        called = y_pred_proba >= thresh\n",
        "        n_called = called.sum()\n",
        "\n",
        "        # SQLs we would capture (true positives)\n",
        "        sqls_captured = (called & (y_true == 1)).sum()\n",
        "\n",
        "        # SQLs we would miss (false negatives)\n",
        "        sqls_missed = (~called & (y_true == 1)).sum()\n",
        "\n",
        "        # Calculate profit\n",
        "        revenue = sqls_captured * value_per_sql\n",
        "        cost = n_called * cost_per_call\n",
        "        profit = revenue - cost\n",
        "\n",
        "        # Precision & Recall at threshold\n",
        "        if n_called > 0:\n",
        "            precision = sqls_captured / n_called\n",
        "        else:\n",
        "            precision = 0\n",
        "\n",
        "        total_sqls = (y_true == 1).sum()\n",
        "        recall = sqls_captured / total_sqls if total_sqls > 0 else 0\n",
        "\n",
        "        profits.append(profit)\n",
        "        metrics.append({\n",
        "            'threshold': thresh,\n",
        "            'n_called': n_called,\n",
        "            'sqls_captured': sqls_captured,\n",
        "            'sqls_missed': sqls_missed,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'revenue': revenue,\n",
        "            'cost': cost,\n",
        "            'profit': profit\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(metrics)\n",
        "\n",
        "\n",
        "def find_optimal_threshold(profit_df):\n",
        "    \"\"\"Find the threshold that maximizes profit.\"\"\"\n",
        "    optimal_idx = profit_df['profit'].idxmax()\n",
        "    return profit_df.loc[optimal_idx]\n",
        "\n",
        "\n",
        "# Calculate profit curve using calibrated probabilities\n",
        "profit_df = calculate_profit_curve(y_test.values, calibrated_probs)\n",
        "\n",
        "# Find optimal threshold\n",
        "optimal = find_optimal_threshold(profit_df)\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"V3 UPGRADE: PROFIT OPTIMIZATION\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\nOPTIMAL THRESHOLD: {optimal['threshold']:.2f}\")\n",
        "print(f\"  Leads to Call: {optimal['n_called']:.0f} ({optimal['n_called']/len(y_test):.1%} of pool)\")\n",
        "print(f\"  SQLs Captured: {optimal['sqls_captured']:.0f} ({optimal['recall']:.1%} recall)\")\n",
        "print(f\"  SQLs Missed: {optimal['sqls_missed']:.0f}\")\n",
        "print(f\"  Precision: {optimal['precision']:.1%}\")\n",
        "print(f\"  Revenue: ${optimal['revenue']:,.0f}\")\n",
        "print(f\"  Cost: ${optimal['cost']:,.0f}\")\n",
        "print(f\"  MAXIMUM PROFIT: ${optimal['profit']:,.0f}\")\n",
        "\n",
        "# Compare to naive strategies\n",
        "naive_all = (y_test.sum() * VALUE_PER_SQL) - (len(y_test) * COST_PER_CALL)\n",
        "naive_none = 0\n",
        "top_20_thresh = np.percentile(calibrated_probs, 80)\n",
        "top_20_idx = profit_df['threshold'].sub(top_20_thresh).abs().idxmin()\n",
        "top_20_profit = profit_df.loc[top_20_idx, 'profit']\n",
        "\n",
        "print(f\"\\nCOMPARISON TO NAIVE STRATEGIES:\")\n",
        "print(f\"  Call Everyone: ${naive_all:,.0f}\")\n",
        "print(f\"  Call No One: ${naive_none:,.0f}\")\n",
        "print(f\"  Call Top 20%: ${top_20_profit:,.0f}\")\n",
        "print(f\"  OPTIMAL: ${optimal['profit']:,.0f}\")\n",
        "print(f\"\\n  Lift vs Call Everyone: +${optimal['profit'] - naive_all:,.0f}\")\n",
        "print(f\"  Lift vs Top 20%: +${optimal['profit'] - top_20_profit:,.0f}\")"
      ],
      "id": "profit-optimization",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: profit-visualization\n",
        "#| fig-cap: 'Profit Curve: Finding the exact threshold that maximizes business ROI.'\n",
        "\n",
        "# ==============================================================================\n",
        "# PROFIT CURVE VISUALIZATION\n",
        "# ==============================================================================\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# TOP LEFT: Profit Curve\n",
        "ax1 = axes[0, 0]\n",
        "ax1.plot(profit_df['threshold'], profit_df['profit'] / 1000,\n",
        "         color=PROJECT_COLS['Profit'], linewidth=2.5)\n",
        "ax1.axvline(x=optimal['threshold'], color=PROJECT_COLS['Gold'],\n",
        "            linestyle='--', linewidth=2, label=f\"Optimal: {optimal['threshold']:.2f}\")\n",
        "ax1.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
        "ax1.scatter([optimal['threshold']], [optimal['profit']/1000],\n",
        "            color=PROJECT_COLS['Gold'], s=150, zorder=5, marker='*')\n",
        "ax1.fill_between(profit_df['threshold'], 0, profit_df['profit']/1000,\n",
        "                  where=profit_df['profit']>0, alpha=0.3, color=PROJECT_COLS['Profit'])\n",
        "ax1.fill_between(profit_df['threshold'], 0, profit_df['profit']/1000,\n",
        "                  where=profit_df['profit']<=0, alpha=0.3, color=PROJECT_COLS['Failure'])\n",
        "\n",
        "ax1.set_xlabel('Classification Threshold', fontsize=11)\n",
        "ax1.set_ylabel('Profit ($K)', fontsize=11)\n",
        "ax1.set_title('The Profit Curve\\n(Find the Sweet Spot)', fontweight='bold')\n",
        "ax1.legend(loc='upper right')\n",
        "ax1.grid(alpha=0.3)\n",
        "\n",
        "# Annotate max profit\n",
        "ax1.annotate(f'MAX PROFIT\\n${optimal[\"profit\"]:,.0f}',\n",
        "             xy=(optimal['threshold'], optimal['profit']/1000),\n",
        "             xytext=(optimal['threshold']+0.15, optimal['profit']/1000 + 5),\n",
        "             fontsize=10, fontweight='bold',\n",
        "             arrowprops=dict(arrowstyle='->', color='black'))\n",
        "\n",
        "# TOP RIGHT: Precision-Recall Trade-off\n",
        "ax2 = axes[0, 1]\n",
        "ax2.plot(profit_df['threshold'], profit_df['precision'],\n",
        "         label='Precision', color=PROJECT_COLS['Highlight'], linewidth=2)\n",
        "ax2.plot(profit_df['threshold'], profit_df['recall'],\n",
        "         label='Recall', color=PROJECT_COLS['Purple'], linewidth=2)\n",
        "ax2.axvline(x=optimal['threshold'], color=PROJECT_COLS['Gold'],\n",
        "            linestyle='--', linewidth=2, label=f\"Optimal Threshold\")\n",
        "\n",
        "ax2.set_xlabel('Classification Threshold', fontsize=11)\n",
        "ax2.set_ylabel('Score', fontsize=11)\n",
        "ax2.set_title('Precision-Recall Trade-off', fontweight='bold')\n",
        "ax2.legend(loc='center right')\n",
        "ax2.grid(alpha=0.3)\n",
        "\n",
        "# BOTTOM LEFT: Leads Called vs SQLs Captured\n",
        "ax3 = axes[1, 0]\n",
        "ax3.plot(profit_df['n_called'], profit_df['sqls_captured'],\n",
        "         color=PROJECT_COLS['Success'], linewidth=2.5)\n",
        "\n",
        "# Mark optimal point\n",
        "opt_called = optimal['n_called']\n",
        "opt_sqls = optimal['sqls_captured']\n",
        "ax3.scatter([opt_called], [opt_sqls], color=PROJECT_COLS['Gold'],\n",
        "            s=150, zorder=5, marker='*', label='Optimal')\n",
        "\n",
        "# Random baseline\n",
        "total_sqls = y_test.sum()\n",
        "ax3.plot([0, len(y_test)], [0, total_sqls], 'k--', alpha=0.5, label='Random')\n",
        "\n",
        "ax3.set_xlabel('Leads Called', fontsize=11)\n",
        "ax3.set_ylabel('SQLs Captured', fontsize=11)\n",
        "ax3.set_title('Efficiency Curve: Leads Called vs SQLs Won', fontweight='bold')\n",
        "ax3.legend(loc='lower right')\n",
        "ax3.grid(alpha=0.3)\n",
        "\n",
        "# BOTTOM RIGHT: Cost-Benefit Analysis\n",
        "ax4 = axes[1, 1]\n",
        "ax4.plot(profit_df['threshold'], profit_df['revenue']/1000,\n",
        "         label='Revenue', color=PROJECT_COLS['Success'], linewidth=2)\n",
        "ax4.plot(profit_df['threshold'], profit_df['cost']/1000,\n",
        "         label='Cost', color=PROJECT_COLS['Failure'], linewidth=2)\n",
        "ax4.plot(profit_df['threshold'], profit_df['profit']/1000,\n",
        "         label='Profit', color=PROJECT_COLS['Gold'], linewidth=2.5)\n",
        "ax4.axvline(x=optimal['threshold'], color='gray', linestyle='--', linewidth=1)\n",
        "ax4.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
        "\n",
        "ax4.set_xlabel('Classification Threshold', fontsize=11)\n",
        "ax4.set_ylabel('Dollars ($K)', fontsize=11)\n",
        "ax4.set_title('Cost-Benefit Breakdown', fontweight='bold')\n",
        "ax4.legend(loc='upper right')\n",
        "ax4.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "profit-visualization",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "# Phase 9: Tournament Results"
      ],
      "id": "633785a5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: results-table\n",
        "\n",
        "# ==============================================================================\n",
        "# TOURNAMENT RESULTS\n",
        "# ==============================================================================\n",
        "\n",
        "results_df = pd.DataFrame({\n",
        "    name: {\n",
        "        'CV AUC': f\"{r['cv_auc']:.4f}\",\n",
        "        'Test AUC': f\"{r['test_auc']:.4f}\",\n",
        "        'PR AUC': f\"{r['pr_auc']:.4f}\",\n",
        "        'Brier Score': f\"{r['brier_score']:.4f}\",\n",
        "        'Log Loss': f\"{r['test_logloss']:.4f}\"\n",
        "    }\n",
        "    for name, r in results.items()\n",
        "}).T\n",
        "\n",
        "results_df = results_df.sort_values('Test AUC', ascending=False)\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"TOURNAMENT FINAL STANDINGS\")\n",
        "print(\"=\" * 70)\n",
        "print(results_df.to_string())\n",
        "\n",
        "# Best model is the Calibrated Ensemble\n",
        "best_model_name = 'Calibrated_Ensemble'\n",
        "best_result = results[best_model_name]\n",
        "print(f\"\\nCHAMPION: {best_model_name} (Test AUC: {best_result['test_auc']:.4f})\")"
      ],
      "id": "results-table",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: roc-curves\n",
        "#| fig-cap: 'ROC & PR Curves: Model comparison across all candidates.'\n",
        "\n",
        "# ==============================================================================\n",
        "# ROC & PR CURVES\n",
        "# ==============================================================================\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "colors = list(PROJECT_COLS.values())[:len(results)]\n",
        "\n",
        "# LEFT: ROC Curves\n",
        "ax1 = axes[0]\n",
        "for i, (name, r) in enumerate(sorted(results.items(), key=lambda x: -x[1]['test_auc'])):\n",
        "    fpr, tpr, _ = roc_curve(y_test, r['test_probs'])\n",
        "    linewidth = 3 if name == best_model_name else 1.5\n",
        "    alpha = 1.0 if name == best_model_name else 0.7\n",
        "    ax1.plot(fpr, tpr, label=f\"{name} ({r['test_auc']:.3f})\",\n",
        "             color=colors[i % len(colors)], linewidth=linewidth, alpha=alpha)\n",
        "\n",
        "ax1.plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
        "ax1.set_xlabel('False Positive Rate')\n",
        "ax1.set_ylabel('True Positive Rate')\n",
        "ax1.set_title('ROC Curves', fontweight='bold')\n",
        "ax1.legend(loc='lower right', fontsize=9)\n",
        "ax1.grid(alpha=0.3)\n",
        "\n",
        "# RIGHT: PR Curves\n",
        "ax2 = axes[1]\n",
        "baseline = y_test.mean()\n",
        "for i, (name, r) in enumerate(sorted(results.items(), key=lambda x: -x[1]['pr_auc'])):\n",
        "    precision, recall, _ = precision_recall_curve(y_test, r['test_probs'])\n",
        "    linewidth = 3 if name == best_model_name else 1.5\n",
        "    alpha = 1.0 if name == best_model_name else 0.7\n",
        "    ax2.plot(recall, precision, label=f\"{name} ({r['pr_auc']:.3f})\",\n",
        "             color=colors[i % len(colors)], linewidth=linewidth, alpha=alpha)\n",
        "\n",
        "ax2.axhline(y=baseline, color='black', linestyle='--', linewidth=1, label=f'Baseline ({baseline:.3f})')\n",
        "ax2.set_xlabel('Recall')\n",
        "ax2.set_ylabel('Precision')\n",
        "ax2.set_title('Precision-Recall Curves', fontweight='bold')\n",
        "ax2.legend(loc='upper right', fontsize=9)\n",
        "ax2.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "roc-curves",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "# Phase 10: SHAP Interpretability"
      ],
      "id": "602854db"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: shap-analysis\n",
        "#| fig-cap: 'SHAP Beeswarm: Feature impact on lead scoring predictions.'\n",
        "\n",
        "# ==============================================================================\n",
        "# SHAP BEESWARM PLOT\n",
        "# ==============================================================================\n",
        "\n",
        "if SHAP_AVAILABLE:\n",
        "    print(\"Computing SHAP values (this may take a moment)...\")\n",
        "\n",
        "    # Use LightGBM or XGBoost for SHAP (best compatibility)\n",
        "    if 'LightGBM' in best_estimators:\n",
        "        shap_model = best_estimators['LightGBM']\n",
        "        shap_name = 'LightGBM'\n",
        "    elif 'XGBoost' in best_estimators:\n",
        "        shap_model = best_estimators['XGBoost']\n",
        "        shap_name = 'XGBoost'\n",
        "    else:\n",
        "        shap_model = best_estimators['Random_Forest']\n",
        "        shap_name = 'Random_Forest'\n",
        "\n",
        "    # Create explainer\n",
        "    explainer = shap.TreeExplainer(shap_model)\n",
        "\n",
        "    # Sample for speed\n",
        "    sample_size = min(500, len(X_test_selected))\n",
        "    sample_idx = np.random.choice(len(X_test_selected), sample_size, replace=False)\n",
        "    X_sample = X_test_selected[sample_idx]\n",
        "\n",
        "    shap_values = explainer.shap_values(X_sample)\n",
        "\n",
        "    # Handle different SHAP output formats\n",
        "    if isinstance(shap_values, list):\n",
        "        shap_values = shap_values[1]  # Class 1 (Success)\n",
        "\n",
        "    # Truncate feature names for display\n",
        "    display_names = [n[:35] + '...' if len(n) > 35 else n\n",
        "                     for n in SELECTED_FEATURE_NAMES[:X_sample.shape[1]]]\n",
        "\n",
        "    # Beeswarm plot\n",
        "    plt.figure(figsize=(14, 10))\n",
        "    shap.summary_plot(shap_values, X_sample,\n",
        "                      feature_names=display_names,\n",
        "                      show=False, max_display=20, plot_size=None)\n",
        "    plt.title(f'SHAP Feature Impact ({shap_name})\\nHow Features Push Scores Up/Down',\n",
        "              fontweight='bold', fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Top features by importance\n",
        "    shap_importance = pd.DataFrame({\n",
        "        'feature': SELECTED_FEATURE_NAMES[:shap_values.shape[1]],\n",
        "        'importance': np.abs(shap_values).mean(axis=0)\n",
        "    }).sort_values('importance', ascending=False)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(f\"SHAP FEATURE IMPORTANCE ({shap_name})\")\n",
        "    print(\"=\" * 70)\n",
        "    print(shap_importance.head(15).to_string(index=False))\n",
        "\n",
        "else:\n",
        "    print(\"SHAP not available. Install with: pip install shap\")\n",
        "\n",
        "    # Fallback: Feature importance from tree model\n",
        "    if 'LightGBM' in best_estimators:\n",
        "        model = best_estimators['LightGBM']\n",
        "        importance = model.feature_importances_\n",
        "    elif 'XGBoost' in best_estimators:\n",
        "        model = best_estimators['XGBoost']\n",
        "        importance = model.feature_importances_\n",
        "    else:\n",
        "        model = best_estimators['Random_Forest']\n",
        "        importance = model.feature_importances_\n",
        "\n",
        "    imp_df = pd.DataFrame({\n",
        "        'feature': SELECTED_FEATURE_NAMES[:len(importance)],\n",
        "        'importance': importance\n",
        "    }).sort_values('importance', ascending=False)\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.barh(range(min(20, len(imp_df))), imp_df.head(20)['importance'].values[::-1],\n",
        "             color=PROJECT_COLS['Success'])\n",
        "    plt.yticks(range(min(20, len(imp_df))), imp_df.head(20)['feature'].values[::-1], fontsize=9)\n",
        "    plt.xlabel('Feature Importance')\n",
        "    plt.title('Feature Importance (Tree-Based)', fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "id": "shap-analysis",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "# Phase 11: THE BOTTOM LINE (V3)"
      ],
      "id": "ea8c15b4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: bottom-line\n",
        "\n",
        "# ==============================================================================\n",
        "# THE BOTTOM LINE - V3 GRANDMASTER EDITION\n",
        "# ==============================================================================\n",
        "\n",
        "# Scale from test set to full Mx pool\n",
        "scale_factor = len(df_mx) / len(X_test)\n",
        "monthly_scale = scale_factor / 12\n",
        "\n",
        "# Monthly projections at optimal threshold\n",
        "monthly_calls = optimal['n_called'] * monthly_scale\n",
        "monthly_sqls = optimal['sqls_captured'] * monthly_scale\n",
        "monthly_profit = optimal['profit'] * monthly_scale\n",
        "annual_profit = monthly_profit * 12\n",
        "\n",
        "# Comparison to random\n",
        "random_sqls_at_same_calls = (optimal['n_called'] / len(y_test)) * y_test.sum()\n",
        "random_profit = (random_sqls_at_same_calls * VALUE_PER_SQL) - (optimal['n_called'] * COST_PER_CALL)\n",
        "lift_vs_random = optimal['sqls_captured'] / random_sqls_at_same_calls if random_sqls_at_same_calls > 0 else 0\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"=\" * 70)\n",
        "print(\"                    THE BOTTOM LINE V3\")\n",
        "print(\"                  GRANDMASTER EDITION\")\n",
        "print(\"=\" * 70)\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(f\"\"\"\n",
        "\n",
        "============================================================================\n",
        "                    WINNING MODEL: {best_model_name}\n",
        "============================================================================\n",
        "\n",
        "    Test AUC-ROC: {best_result['test_auc']:.4f}\n",
        "    Brier Score:  {best_result['brier_score']:.4f} (Calibrated)\n",
        "    PR-AUC:       {best_result['pr_auc']:.4f}\n",
        "\n",
        "============================================================================\n",
        "                    V3 PROFIT OPTIMIZATION\n",
        "============================================================================\n",
        "\n",
        "    OPTIMAL THRESHOLD: {optimal['threshold']:.2f}\n",
        "\n",
        "    At this threshold:\n",
        "      - Call {optimal['n_called']:.0f} leads ({optimal['n_called']/len(y_test):.1%} of pool)\n",
        "      - Capture {optimal['sqls_captured']:.0f} SQLs ({optimal['recall']:.1%} recall)\n",
        "      - Precision: {optimal['precision']:.1%}\n",
        "      - Lift vs Random: {lift_vs_random:.2f}x\n",
        "\n",
        "    TEST SET PROFIT: ${optimal['profit']:,.0f}\n",
        "\n",
        "============================================================================\n",
        "                    SCALED PROJECTIONS\n",
        "============================================================================\n",
        "\n",
        "    MONTHLY (at Optimal Threshold):\n",
        "      - Leads to Call:     {monthly_calls:,.0f}\n",
        "      - SQLs Captured:     {monthly_sqls:,.0f}\n",
        "      - Profit:            ${monthly_profit:,.0f}\n",
        "\n",
        "    ANNUAL:\n",
        "      - Profit:            ${annual_profit:,.0f}\n",
        "\n",
        "============================================================================\n",
        "                    V3 UPGRADES SUMMARY\n",
        "============================================================================\n",
        "\n",
        "    1. PROBABILITY CALIBRATION\n",
        "       Brier Score improved: {results['Voting_Ensemble']['brier_score']:.4f} -> {calibrated_brier:.4f}\n",
        "       Probabilities are now mathematically accurate.\n",
        "\n",
        "    2. AUTOMATED FEATURE SELECTION\n",
        "       Reduced from {len(selected_mask)} to {n_selected} features\n",
        "       Noise reduction improves generalization.\n",
        "\n",
        "    3. PROFIT MAXIMIZATION\n",
        "       Optimal threshold: {optimal['threshold']:.2f}\n",
        "       Max profit: ${optimal['profit']:,.0f} (vs ${random_profit:,.0f} random)\n",
        "\n",
        "============================================================================\n",
        "\"\"\")"
      ],
      "id": "bottom-line",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: executive-dashboard\n",
        "#| fig-cap: 'Executive Dashboard: Complete V3 model performance summary.'\n",
        "\n",
        "# ==============================================================================\n",
        "# EXECUTIVE SUMMARY DASHBOARD (V3)\n",
        "# ==============================================================================\n",
        "\n",
        "fig = plt.figure(figsize=(18, 14))\n",
        "gs = fig.add_gridspec(3, 3, hspace=0.35, wspace=0.3)\n",
        "\n",
        "# 1. Model Comparison Bar\n",
        "ax1 = fig.add_subplot(gs[0, 0])\n",
        "model_aucs = [(name, r['test_auc']) for name, r in results.items()]\n",
        "model_aucs.sort(key=lambda x: x[1], reverse=True)\n",
        "colors = [PROJECT_COLS['Success'] if name == best_model_name else PROJECT_COLS['Neutral']\n",
        "          for name, _ in model_aucs]\n",
        "ax1.barh([m[0] for m in model_aucs], [m[1] for m in model_aucs], color=colors)\n",
        "ax1.set_xlabel('Test AUC')\n",
        "ax1.set_title('Model Comparison', fontweight='bold')\n",
        "ax1.set_xlim(0.5, 1.0)\n",
        "for i, (name, auc_val) in enumerate(model_aucs):\n",
        "    ax1.text(auc_val + 0.01, i, f'{auc_val:.4f}', va='center', fontsize=9)\n",
        "\n",
        "# 2. Profit Curve (Highlight)\n",
        "ax2 = fig.add_subplot(gs[0, 1])\n",
        "ax2.plot(profit_df['threshold'], profit_df['profit'] / 1000,\n",
        "         color=PROJECT_COLS['Profit'], linewidth=2.5)\n",
        "ax2.axvline(x=optimal['threshold'], color=PROJECT_COLS['Gold'], linestyle='--', linewidth=2)\n",
        "ax2.scatter([optimal['threshold']], [optimal['profit']/1000],\n",
        "            color=PROJECT_COLS['Gold'], s=150, zorder=5, marker='*')\n",
        "ax2.fill_between(profit_df['threshold'], 0, profit_df['profit']/1000,\n",
        "                  where=profit_df['profit']>0, alpha=0.3, color=PROJECT_COLS['Profit'])\n",
        "ax2.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
        "ax2.set_xlabel('Threshold')\n",
        "ax2.set_ylabel('Profit ($K)')\n",
        "ax2.set_title(f'Profit Curve (Optimal: {optimal[\"threshold\"]:.2f})', fontweight='bold')\n",
        "ax2.grid(alpha=0.3)\n",
        "\n",
        "# 3. Calibration Curve\n",
        "ax3 = fig.add_subplot(gs[0, 2])\n",
        "ax3.plot([0, 1], [0, 1], 'k--', label='Perfect')\n",
        "ax3.plot(prob_pred_uncal, prob_true_uncal, 'o-', color=PROJECT_COLS['Failure'], label='Uncalibrated')\n",
        "ax3.plot(prob_pred_cal, prob_true_cal, 's-', color=PROJECT_COLS['Success'], label='Calibrated')\n",
        "ax3.set_xlabel('Predicted Probability')\n",
        "ax3.set_ylabel('True Probability')\n",
        "ax3.set_title('Calibration Curve', fontweight='bold')\n",
        "ax3.legend(loc='upper left', fontsize=9)\n",
        "ax3.grid(alpha=0.3)\n",
        "\n",
        "# 4. Score Distribution\n",
        "ax4 = fig.add_subplot(gs[1, 0])\n",
        "ax4.hist(calibrated_probs[y_test == 0], bins=30, alpha=0.6, label='Fail',\n",
        "         color=PROJECT_COLS['Failure'], density=True)\n",
        "ax4.hist(calibrated_probs[y_test == 1], bins=30, alpha=0.6, label='Success',\n",
        "         color=PROJECT_COLS['Success'], density=True)\n",
        "ax4.axvline(x=optimal['threshold'], color=PROJECT_COLS['Gold'], linestyle='--',\n",
        "            linewidth=2, label=f'Optimal: {optimal[\"threshold\"]:.2f}')\n",
        "ax4.set_xlabel('Predicted Probability')\n",
        "ax4.set_ylabel('Density')\n",
        "ax4.set_title('Score Distribution by Outcome', fontweight='bold')\n",
        "ax4.legend()\n",
        "\n",
        "# 5. Confusion Matrix at Optimal Threshold\n",
        "ax5 = fig.add_subplot(gs[1, 1])\n",
        "optimal_preds = (calibrated_probs >= optimal['threshold']).astype(int)\n",
        "cm = confusion_matrix(y_test, optimal_preds)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax5,\n",
        "            xticklabels=['Not Called', 'Called'],\n",
        "            yticklabels=['Not SQL', 'SQL'])\n",
        "ax5.set_title(f'Confusion Matrix\\n(Threshold: {optimal[\"threshold\"]:.2f})', fontweight='bold')\n",
        "\n",
        "# 6. Precision vs Recall\n",
        "ax6 = fig.add_subplot(gs[1, 2])\n",
        "ax6.plot(profit_df['recall'], profit_df['precision'],\n",
        "         color=PROJECT_COLS['Highlight'], linewidth=2)\n",
        "ax6.scatter([optimal['recall']], [optimal['precision']],\n",
        "            color=PROJECT_COLS['Gold'], s=150, zorder=5, marker='*',\n",
        "            label=f'Optimal ({optimal[\"precision\"]:.1%} P, {optimal[\"recall\"]:.1%} R)')\n",
        "ax6.axhline(y=y_test.mean(), color='black', linestyle='--', alpha=0.5)\n",
        "ax6.set_xlabel('Recall (SQLs Captured)')\n",
        "ax6.set_ylabel('Precision')\n",
        "ax6.set_title('Precision-Recall Trade-off', fontweight='bold')\n",
        "ax6.legend(loc='upper right')\n",
        "ax6.grid(alpha=0.3)\n",
        "\n",
        "# 7-9. KPI Cards\n",
        "ax7 = fig.add_subplot(gs[2, :])\n",
        "ax7.axis('off')\n",
        "\n",
        "kpi_text = f\"\"\"\n",
        "+---------------------------+---------------------------+---------------------------+---------------------------+\n",
        "|      BEST MODEL           |      TEST AUC             |    OPTIMAL THRESHOLD      |    MAX ANNUAL PROFIT      |\n",
        "|   {best_model_name:<22} |        {best_result['test_auc']:.4f}             |          {optimal['threshold']:.2f}              |     ${annual_profit:>14,.0f}     |\n",
        "+---------------------------+---------------------------+---------------------------+---------------------------+\n",
        "|     BRIER SCORE           |     PRECISION @ OPT       |     RECALL @ OPT          |     LIFT vs RANDOM        |\n",
        "|        {calibrated_brier:.4f}             |        {optimal['precision']:.1%}              |        {optimal['recall']:.1%}              |          {lift_vs_random:.2f}x             |\n",
        "+---------------------------+---------------------------+---------------------------+---------------------------+\n",
        "\"\"\"\n",
        "\n",
        "ax7.text(0.5, 0.5, kpi_text, fontsize=11, fontfamily='monospace',\n",
        "         ha='center', va='center', transform=ax7.transAxes,\n",
        "         bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))\n",
        "\n",
        "plt.suptitle(f'MasterControl Mx Lead Scoring V3 - GRANDMASTER EDITION',\n",
        "             fontsize=18, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "executive-dashboard",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: recommendations\n",
        "\n",
        "# ==============================================================================\n",
        "# RECOMMENDATIONS\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"                    RECOMMENDATIONS\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\"\"\n",
        "\n",
        "1. DEPLOY THE CALIBRATED MODEL\n",
        "   - Use threshold {optimal['threshold']:.2f} for lead prioritization\n",
        "   - Probabilities are now interpretable as true conversion likelihood\n",
        "\n",
        "2. IMPLEMENT TIERED ROUTING\n",
        "   - Tier 1 (p >= {optimal['threshold']:.2f}): Route to senior SDRs (call within 24h)\n",
        "   - Tier 2 (p >= 0.10): Standard SDR queue (call within 72h)\n",
        "   - Tier 3 (p < 0.10): Nurture campaign only\n",
        "\n",
        "3. SET SLAs BY SCORE\n",
        "   - High-score leads demand faster follow-up\n",
        "   - Each day of delay costs {COST_PER_CALL * 0.1:.0f}%+ in conversion\n",
        "\n",
        "4. MONITOR CALIBRATION DRIFT\n",
        "   - Track Brier score monthly\n",
        "   - Re-calibrate if Brier > 0.15\n",
        "\n",
        "5. A/B TEST THE THRESHOLD\n",
        "   - Test optimal threshold vs top-20% strategy\n",
        "   - Measure actual profit lift over 90 days\n",
        "\n",
        "6. EXPECTED ROI\n",
        "   - Annual Profit Lift: ${annual_profit:,.0f}\n",
        "   - Break-even: {COST_PER_CALL / VALUE_PER_SQL:.1%} conversion (we achieve {optimal['precision']:.1%})\n",
        "\"\"\")\n",
        "print(\"=\" * 70)"
      ],
      "id": "recommendations",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "# Appendix: Technical Methodology (V3)\n",
        "\n",
        "**V3 Upgrades Explained:**\n",
        "\n",
        "1.  **Profit Maximization:** Traditional ML optimizes for AUC or log-loss. But business value comes from the decision threshold. We calculate profit at every threshold: `Profit = (SQLs × $6,000) - (Calls × $50)` and find the exact point that maximizes ROI.\n",
        "\n",
        "2.  **Probability Calibration:** Boosting models produce well-ranked but miscalibrated probabilities. A \"0.7 score\" doesn't mean 70% true probability. Isotonic regression (via `CalibratedClassifierCV`) adjusts predictions to match empirical frequencies, making revenue projections mathematically accurate.\n",
        "\n",
        "3.  **Automated Feature Selection:** We use `SelectFromModel` with a Random Forest to drop zero/low-importance features. This reduces overfitting and can boost Test AUC by removing noise.\n",
        "\n",
        "**Business Parameters:**\n",
        "\n",
        "-   Cost per Call: \\$50 (SDR time, tools, opportunity cost)\n",
        "-   Value per SQL: \\$6,000 (= \\$50K deal × 12% SQL-to-deal rate)\n",
        "-   Break-even threshold: 0.83% conversion required per call\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "*Model V3 (Grandmaster Edition) generated for MSBA Capstone Case Competition - Spring 2026*"
      ],
      "id": "4f207e67"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "playwright_env",
      "language": "python",
      "display_name": "Python (playwright_env)",
      "path": "C:\\Users\\thoma\\AppData\\Roaming\\jupyter\\kernels\\playwright_env"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}