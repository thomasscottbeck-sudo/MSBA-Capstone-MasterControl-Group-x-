---
title: "MasterControl QAL Performance: Exploratory Data Analysis"
subtitle: "Understanding the Mx Conversion Gap"
author: "Thomas Beck"
date: "Spring 2026"
format:
  html:
    embed-resources: true
    theme: flatly
    highlight-style: tango
    toc: true
    toc-depth: 3
    toc-location: left
    number-sections: false
    df-print: paged
    code-fold: show
    code-tools: true
execute:
  echo: false
  warning: false
  message: false
  fig-width: 8
  fig-height: 5
  fig-dpi: 100
  out-width: "100%"
editor_options:
  chunk_output_type: inline
---

```{python}
#| label: setup
#| include: false

# =============================================================================
# Core Imports and Configuration
# =============================================================================

import subprocess
import sys
import warnings
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import re
from scipy import stats
from scipy.stats import chi2_contingency, beta, mannwhitneyu
from sklearn.feature_extraction.text import CountVectorizer
from IPython.display import Markdown, display

warnings.filterwarnings('ignore')
np.random.seed(42)
```

```{python}
#| label: dependencies
#| include: false

# =============================================================================
# Dependency Management
# =============================================================================

def install_if_missing(package_name, import_name=None, pip_name=None):
    """Install a package if not already available."""
    import_name = import_name or package_name.lower()
    pip_name = pip_name or import_name
    try:
        __import__(import_name)
    except ImportError:
        subprocess.check_call(
            [sys.executable, "-m", "pip", "install", pip_name, "-q"],
            stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL
        )

for pkg in [("pyprojroot", None, None), ("tabulate", None, None)]:
    install_if_missing(*pkg)

from pyprojroot import here
from tabulate import tabulate
```

```{python}
#| label: configuration
#| include: false

# =============================================================================
# Path Configuration
# =============================================================================

DATA_DIR   = here("data")
OUTPUT_DIR = here("output")
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

RAW_DATA_PATH     = here("data/QAL Performance for MSBA.csv")
CLEANED_DATA_PATH = here("output/Cleaned_QAL_Performance_for_MSBA.csv")

# =============================================================================
# Color Palette
# =============================================================================

COL_SUCCESS  = '#00534B'   # Teal — positive outcomes
COL_RISK     = '#F05627'   # Orange — gaps / risk
COL_NEUTRAL  = '#95a5a6'   # Gray — baseline
COL_ACCENT   = '#2980b9'   # Blue — highlights
COL_GOLD     = '#f39c12'   # Gold — emphasis
COL_PURPLE   = '#9b59b6'   # Purple — secondary
COL_PROFIT   = '#27ae60'   # Green — profit

# =============================================================================
# Statistical Thresholds
# =============================================================================

ALPHA = 0.05
MIN_SAMPLE_SIZE = 30
BAYESIAN_PRIOR_ALPHA = 1
BAYESIAN_PRIOR_BETA  = 1

# =============================================================================
# Visualization Defaults
# =============================================================================

sns.set_theme(style="whitegrid", context="notebook")
plt.rcParams.update({
    'figure.figsize': (8, 5),
    'figure.dpi': 100,
    'axes.titleweight': 'bold',
    'font.family': 'sans-serif',
    'savefig.dpi': 300,
    'savefig.bbox': 'tight'
})

# =============================================================================
# Table Formatting Helper
# =============================================================================

def print_table(data, caption=""):
    """Format a DataFrame or list-of-lists as a styled markdown table."""
    if isinstance(data, pd.DataFrame):
        md = data.to_markdown(index=False)
    else:
        md = tabulate(data[1:], headers=data[0], tablefmt="pipe")
    if caption:
        display(Markdown(f"**{caption}**\n\n{md}"))
    else:
        display(Markdown(md))
```

::: {.callout-note}
## Project Context

This document is my individual exploratory analysis for MasterControl's QAL (Qualified Accepted Lead) pipeline data. The objective is to diagnose why the Mx product line converts leads to SQL at a lower rate than Qx, and to identify which lead segments, title signals, and pipeline behaviors explain the gap. The features engineered here feed directly into the team's modeling phase.
:::

# Executive Summary

MasterControl's Mx product converts leads to SQL at approximately 12.7% compared to Qx at approximately 19.7%---a 7 percentage-point gap that represents significant unrealized pipeline value.

```{python}
#| label: exec-summary-table

print_table(
    [["KPI", "Mx", "Qx", "Gap"],
     ["Conversion Rate", "12.7%", "19.7%", "-7.0 pp"],
     ["Median Days-to-SQL", "89", "66", "+23 days"],
     ["Decision-Maker Share", "34%", "41%", "-7 pp"],
     ["Recycled Lead Rate", "18%", "11%", "+7 pp"]],
    caption="Mx vs Qx Performance Summary"
)
```

Four findings stood out during this analysis:

1. **Velocity gap:** Mx leads take 23 days longer to convert, pointing to a sales enablement issue rather than a targeting issue.
2. **High-converting segment:** Directors in Pharma / In-House convert at 28% for Mx---more than double the product average.
3. **Recoverable leads:** 847 recycled Mx leads are potentially recoverable with targeted nurture.
4. **Scope matters:** Leads with "Global" in their title convert at 2.1x the rate of "Site"-level contacts.

---

# Data Preparation & Feature Engineering

The raw CRM data requires feature engineering to surface useful signals. I built title-parsing logic to extract seniority, functional domain, and scope from free-text contact titles. Record completeness serves as a rough proxy for buyer seriousness---leads with more filled-in fields tend to convert at higher rates.

```{python}
#| label: data-pipeline
#| include: false

# =============================================================================
# Data Loading and Feature Engineering
# =============================================================================

def clean_and_engineer(filepath=None):
    """
    Load raw CRM data and engineer features for analysis.

    Engineered features:
    - title_seniority: Decision-making authority level (C-Suite through IC)
    - title_function: Functional domain (Quality, Regulatory, Mfg/Ops, etc.)
    - title_scope: Geographic/organizational scope (Global, Regional, Site, Standard)
    - is_decision_maker: Binary flag for Director+ seniority
    - record_completeness: Proportion of key fields filled (0-1)
    - Temporal features: cohort year/quarter/month, lead age in days
    """

    if filepath is None:
        filepath = RAW_DATA_PATH

    if not filepath.exists():
        raise FileNotFoundError(f"Data file not found at {filepath}")

    df = pd.read_csv(filepath)

    # Standardize headers
    df.columns = [c.strip().lower().replace(' ', '_').replace('/', '_').replace('-', '_')
                  for c in df.columns]

    # Target definition: SQL, SQO, or Won = success
    success_stages = ['SQL', 'SQO', 'Won']
    df['is_success'] = df['next_stage__c'].isin(success_stages).astype(int)

    # Outcome tiers for funnel analysis
    def classify_outcome(stage):
        if stage in ['SQL', 'SQO', 'Won']:
            return 'Success'
        elif stage == 'Recycled':
            return 'Near-Miss'
        else:
            return 'Lost'

    df['outcome_tier'] = df['next_stage__c'].apply(classify_outcome)

    # Product segmentation
    def segment_product(sol):
        if str(sol) == 'Mx': return 'Mx'
        elif str(sol) == 'Qx': return 'Qx'
        return 'Other'

    df['product_segment'] = df['solution_rollup'].apply(segment_product)

    # -------------------------------------------------------------------------
    # Title parsing: seniority
    # -------------------------------------------------------------------------
    def parse_seniority(t):
        if pd.isna(t): return 'Unknown'
        t = str(t).lower()
        if re.search(r'\b(ceo|cfo|coo|cto|cio|chief|c-level|president)\b', t): return 'C-Suite'
        if re.search(r'\b(svp|senior vice president|evp)\b', t): return 'SVP'
        if re.search(r'\b(vp|vice president)\b', t): return 'VP'
        if re.search(r'\b(director|head of)\b', t): return 'Director'
        if re.search(r'\b(manager|mgr|supervisor|lead)\b', t): return 'Manager'
        if re.search(r'\b(analyst|engineer|specialist|associate|coordinator)\b', t): return 'IC'
        return 'Other'

    # Title parsing: function
    def parse_function(t):
        if pd.isna(t): return 'Unknown'
        t = str(t).lower()
        if re.search(r'\b(quality|qa|qc|qms|compliance|validation|capa)\b', t): return 'Quality'
        if re.search(r'\b(regulatory|reg affairs|submissions)\b', t): return 'Regulatory'
        if re.search(r'\b(manufacturing|production|operations|ops|plant|supply)\b', t): return 'Mfg/Ops'
        if re.search(r'\b(it|information tech|software|systems|data)\b', t): return 'IT'
        if re.search(r'\b(r&d|research|development|scientist|clinical|lab)\b', t): return 'R&D'
        if re.search(r'\b(project|program|pmo)\b', t): return 'PMO'
        return 'Other'

    # Title parsing: scope
    def parse_power_modifier(t):
        if pd.isna(t): return 'Unknown'
        t = str(t).lower()
        if re.search(r'\b(global|worldwide|international|corporate|enterprise)\b', t): return 'Global'
        if re.search(r'\b(regional|division|group)\b', t): return 'Regional'
        if re.search(r'\b(site|plant|facility|local)\b', t): return 'Site'
        return 'Standard'

    df['title_seniority'] = df['contact_lead_title'].apply(parse_seniority)
    df['title_function']  = df['contact_lead_title'].apply(parse_function)
    df['title_scope']     = df['contact_lead_title'].apply(parse_power_modifier)

    # Decision maker flag (Director+)
    df['is_decision_maker'] = df['title_seniority'].isin(
        ['C-Suite', 'SVP', 'VP', 'Director']).astype(int)

    # -------------------------------------------------------------------------
    # Record completeness score
    # -------------------------------------------------------------------------
    completeness_cols = [
        'acct_manufacturing_model', 'acct_primary_site_function',
        'acct_target_industry', 'acct_territory_rollup', 'acct_tier_rollup'
    ]

    def calc_completeness(row):
        filled = sum(1 for col in completeness_cols
                     if col in row.index and pd.notna(row[col]) and str(row[col]) != 'Unknown')
        return filled / len(completeness_cols)

    df['record_completeness'] = df.apply(calc_completeness, axis=1)
    df['completeness_tier'] = pd.cut(df['record_completeness'],
                                      bins=[-0.01, 0.4, 0.8, 1.01],
                                      labels=['Low', 'Medium', 'High'])

    # -------------------------------------------------------------------------
    # Temporal features
    # -------------------------------------------------------------------------
    df['cohort_date']    = pd.to_datetime(df['qal_cohort_date'], errors='coerce')
    df['cohort_year']    = df['cohort_date'].dt.year
    df['cohort_quarter'] = df['cohort_date'].dt.to_period('Q').astype(str)
    df['cohort_month']   = df['cohort_date'].dt.to_period('M').astype(str)

    snapshot_date = df['cohort_date'].max()
    df['lead_age_days'] = (snapshot_date - df['cohort_date']).dt.days

    # Fill missing categoricals
    cols_to_fill = ['acct_manufacturing_model', 'acct_primary_site_function',
                    'acct_target_industry', 'acct_territory_rollup']
    for c in cols_to_fill:
        if c in df.columns:
            df[c] = df[c].fillna('Unknown')

    return df

df = clean_and_engineer()
```

```{python}
#| label: dataset-overview

df_mx = df[df['product_segment'] == 'Mx']
df_qx = df[df['product_segment'] == 'Qx']

overview = pd.DataFrame({
    'Metric': [
        'Total Records', 'Mx Leads', 'Qx Leads',
        'Overall Conversion Rate', 'Mx Conversion Rate', 'Qx Conversion Rate',
        'Decision Makers (Director+)', 'Recycled (Near-Miss)'
    ],
    'Value': [
        f"{len(df):,}", f"{len(df_mx):,}", f"{len(df_qx):,}",
        f"{df['is_success'].mean():.1%}", f"{df_mx['is_success'].mean():.1%}",
        f"{df_qx['is_success'].mean():.1%}",
        f"{df['is_decision_maker'].sum():,} ({df['is_decision_maker'].mean():.1%})",
        f"{len(df[df['outcome_tier']=='Near-Miss']):,}"
    ]
})

print_table(overview, caption="Dataset Overview")
```

The pipeline loads the QAL records, standardizes column names, and engineers five feature families from the raw CRM fields. I parsed seniority from free-text titles using regex (C-Suite → SVP → VP → Director → Manager → IC), extracted functional domain (Quality, Regulatory, Mfg/Ops, IT, R&D, PMO), and identified geographic scope keywords (Global, Regional, Site). A binary decision-maker flag and a record completeness score round out the feature set. The target variable `is_success` is defined as any lead reaching SQL, SQO, or Won stage.

---

# The Conversion Gap

This section establishes the Mx vs Qx performance difference with statistical rigor and visualizes where leads exit the pipeline.

```{python}
#| label: bayesian-util
#| include: false

def bayesian_conversion_rate(successes, n, alpha=BAYESIAN_PRIOR_ALPHA, beta_param=BAYESIAN_PRIOR_BETA):
    """
    Bayesian credible interval using Beta-Binomial conjugacy.
    This avoids the overconfidence that frequentist CIs produce
    with small sample sizes.
    """
    post_alpha = alpha + successes
    post_beta  = beta_param + (n - successes)

    mean   = post_alpha / (post_alpha + post_beta)
    ci_low  = beta.ppf(0.025, post_alpha, post_beta)
    ci_high = beta.ppf(0.975, post_alpha, post_beta)

    return mean, ci_low, ci_high
```

## Mx vs Qx Conversion Comparison

```{python}
#| label: gap-bar-chart
#| fig-cap: "Qx outperforms Mx by approximately 7 percentage points in lead-to-SQL conversion."

df_main = df[df['product_segment'].isin(['Mx', 'Qx'])]

results = []
for product in ['Mx', 'Qx']:
    subset = df_main[df_main['product_segment'] == product]
    n = len(subset)
    successes = subset['is_success'].sum()
    rate, ci_low, ci_high = bayesian_conversion_rate(successes, n)
    results.append({
        'product': product, 'n': n, 'successes': successes,
        'rate': rate, 'ci_low': ci_low, 'ci_high': ci_high
    })

results_df = pd.DataFrame(results)

fig, ax = plt.subplots(figsize=(8, 5))

colors = [COL_SUCCESS, COL_RISK]
bars = ax.bar(results_df['product'], results_df['rate'], color=colors,
              edgecolor='white', linewidth=2)

for i, row in results_df.iterrows():
    ax.errorbar(i, row['rate'],
               yerr=[[row['rate'] - row['ci_low']], [row['ci_high'] - row['rate']]],
               fmt='none', color='black', capsize=10, capthick=2, linewidth=2)
    ax.text(i, row['rate'] + 0.025, f"{row['rate']:.1%}",
           ha='center', va='bottom', fontsize=16, fontweight='bold')
    ax.text(i, row['ci_low'] - 0.015, f"n={row['n']:,}",
           ha='center', va='top', fontsize=10, color='gray')

ax.set_ylabel('Conversion Rate (Lead → SQL+)', fontsize=12)
ax.set_title('Mx vs Qx Conversion Rate\n(with 95% Bayesian Credible Intervals)',
            fontweight='bold', fontsize=14)
ax.set_ylim(0, 0.30)
ax.axhline(y=df_main['is_success'].mean(), color='gray', linestyle='--',
           alpha=0.5, label='Overall Avg')
ax.legend(loc='upper right')

gap = results_df[results_df['product']=='Qx']['rate'].values[0] - \
      results_df[results_df['product']=='Mx']['rate'].values[0]
ax.annotate(f"{gap:.1%} gap in conversion between Mx and Qx",
            xy=(0.5, 0.02), xycoords='axes fraction',
            fontsize=11, fontstyle='italic', color=COL_RISK, ha='center')

sns.despine()
plt.tight_layout()
plt.savefig(here("output/eda_conversion_gap.png"), dpi=300)
plt.show()
```

The credible intervals confirm this is not a sampling artifact---the gap is statistically meaningful. Mx converts at roughly two-thirds the rate of Qx, and the 95% Bayesian intervals do not overlap. I used a Beta-Binomial conjugate model here instead of frequentist confidence intervals because it handles small sub-segment sample sizes more gracefully, which matters for the interaction analyses later in this report.

## Funnel Drop-Off

```{python}
#| label: funnel-dropoff
#| fig-cap: "Stage distribution showing where Mx and Qx leads exit the pipeline."

stage_order = ['Disqualified', 'Recycled', 'SQL', 'SQO', 'Won']
df_products = df[df['product_segment'].isin(['Mx', 'Qx'])].copy()

stage_counts = df_products.groupby(['product_segment', 'next_stage__c']).size().unstack(fill_value=0)
existing_stages = [s for s in stage_order if s in stage_counts.columns]
stage_counts = stage_counts[existing_stages]
stage_pct = stage_counts.div(stage_counts.sum(axis=1), axis=0) * 100

fig, ax = plt.subplots(figsize=(8, 5))

x = np.arange(len(existing_stages))
width = 0.35

mx_pct = stage_pct.loc['Mx'] if 'Mx' in stage_pct.index else pd.Series([0]*len(existing_stages))
qx_pct = stage_pct.loc['Qx'] if 'Qx' in stage_pct.index else pd.Series([0]*len(existing_stages))

bars1 = ax.bar(x - width/2, mx_pct, width, label='Mx', color=COL_SUCCESS, alpha=0.8)
bars2 = ax.bar(x + width/2, qx_pct, width, label='Qx', color=COL_RISK, alpha=0.8)

for bar in bars1:
    height = bar.get_height()
    if height > 0:
        ax.annotate(f'{height:.1f}%',
                    xy=(bar.get_x() + bar.get_width() / 2, height),
                    xytext=(0, 3), textcoords="offset points",
                    ha='center', va='bottom', fontsize=9)

for bar in bars2:
    height = bar.get_height()
    if height > 0:
        ax.annotate(f'{height:.1f}%',
                    xy=(bar.get_x() + bar.get_width() / 2, height),
                    xytext=(0, 3), textcoords="offset points",
                    ha='center', va='bottom', fontsize=9)

ax.set_xlabel('Pipeline Stage', fontsize=12)
ax.set_ylabel('Percentage of Leads', fontsize=12)
ax.set_title('Funnel Stage Distribution: Mx vs Qx', fontweight='bold', fontsize=14)
ax.set_xticks(x)
ax.set_xticklabels(existing_stages)
ax.legend()
ax.set_ylim(0, max(mx_pct.max(), qx_pct.max()) * 1.2)

recycled_mx = mx_pct['Recycled'] if 'Recycled' in mx_pct.index else 0
recycled_qx = qx_pct['Recycled'] if 'Recycled' in qx_pct.index else 0
ax.annotate(f"Mx has {recycled_mx - recycled_qx:.1f}pp more recycled leads than Qx",
            xy=(0.5, 0.95), xycoords='axes fraction',
            fontsize=10, fontstyle='italic', color=COL_ACCENT,
            ha='center', va='top',
            bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))

sns.despine()
plt.tight_layout()
plt.savefig(here("output/eda_funnel_dropoff.png"), dpi=300)
plt.show()
```

```{python}
#| label: funnel-table

funnel_df = pd.DataFrame({
    'Stage': existing_stages,
    'Mx (%)': [f"{mx_pct[s]:.1f}" if s in mx_pct.index else "0.0" for s in existing_stages],
    'Qx (%)': [f"{qx_pct[s]:.1f}" if s in qx_pct.index else "0.0" for s in existing_stages]
})
print_table(funnel_df, caption="Funnel Stage Distribution")
```

The funnel breakdown reveals where the gap materializes. Mx has a noticeably higher share of recycled leads than Qx, meaning more Mx leads stall in the pipeline rather than converting or being cleanly disqualified. I found this interesting because it suggests these are not bad leads---they were not rejected on quality grounds but simply did not progress. That distinction matters because it frames the recycled population as a recovery opportunity rather than a sunk cost.

---

# Velocity and Recycled Lead Analysis

If Mx leads take longer to convert, the issue may be sales enablement (training, content, follow-up SLAs) rather than lead targeting. This section also maps the recycled lead population to identify which segments hold the most recovery potential.

## Pipeline Velocity

```{python}
#| label: velocity-analysis
#| fig-cap: "Mx leads take longer to convert, suggesting a velocity problem rather than a quality problem."

df_velocity = df[df['product_segment'].isin(['Mx', 'Qx'])].copy()
df_success = df_velocity[df_velocity['is_success'] == 1].copy()

velocity_stats = df_success.groupby('product_segment').agg(
    median_age=('lead_age_days', 'median'),
    mean_age=('lead_age_days', 'mean'),
    p25_age=('lead_age_days', lambda x: x.quantile(0.25)),
    p75_age=('lead_age_days', lambda x: x.quantile(0.75)),
    n_wins=('is_success', 'sum')
).reset_index()

# Mann-Whitney U test (non-parametric)
mx_ages = df_success[df_success['product_segment'] == 'Mx']['lead_age_days'].dropna()
qx_ages = df_success[df_success['product_segment'] == 'Qx']['lead_age_days'].dropna()

mw_p_val = None
if len(mx_ages) > 5 and len(qx_ages) > 5:
    stat, mw_p_val = mannwhitneyu(mx_ages, qx_ages, alternative='two-sided')

fig, axes = plt.subplots(1, 2, figsize=(8, 4))

# Left: histogram
ax1 = axes[0]
for product, color in [('Mx', COL_SUCCESS), ('Qx', COL_RISK)]:
    data = df_success[df_success['product_segment'] == product]['lead_age_days'].dropna()
    if len(data) > 0:
        ax1.hist(data, bins=30, alpha=0.6, label=f'{product} (n={len(data)})',
                 color=color, density=True)

ax1.set_xlabel('Lead Age at Conversion (Days)', fontsize=11)
ax1.set_ylabel('Density', fontsize=11)
ax1.set_title('Time-to-Convert Distribution', fontweight='bold')
ax1.legend()

# Right: boxplot
ax2 = axes[1]
df_plot = df_success[df_success['product_segment'].isin(['Mx', 'Qx'])]
box_colors = [COL_SUCCESS, COL_RISK]
bp = df_plot.boxplot(column='lead_age_days', by='product_segment', ax=ax2,
                     patch_artist=True, return_type='dict')

for patch, color in zip(bp['lead_age_days']['boxes'], box_colors):
    patch.set_facecolor(color)
    patch.set_alpha(0.7)

ax2.set_xlabel('Product', fontsize=11)
ax2.set_ylabel('Lead Age at Conversion (Days)', fontsize=11)
ax2.set_title('Time-to-Convert by Product', fontweight='bold')
plt.suptitle('')

for a in axes:
    sns.despine(ax=a)

plt.tight_layout()
plt.savefig(here("output/eda_velocity.png"), dpi=300)
plt.show()
```

```{python}
#| label: velocity-table

vel_df = velocity_stats.copy()
vel_df.columns = ['Product', 'Median Days', 'Mean Days', 'P25', 'P75', 'N Converted']
vel_df['Median Days'] = vel_df['Median Days'].apply(lambda x: f"{x:.0f}")
vel_df['Mean Days']   = vel_df['Mean Days'].apply(lambda x: f"{x:.0f}")
vel_df['P25']         = vel_df['P25'].apply(lambda x: f"{x:.0f}")
vel_df['P75']         = vel_df['P75'].apply(lambda x: f"{x:.0f}")
vel_df['N Converted'] = vel_df['N Converted'].apply(lambda x: f"{int(x):,}")

print_table(vel_df, caption="Pipeline Velocity Statistics")
```

The histogram and boxplot both confirm a rightward shift for Mx: converted Mx leads sit in the pipeline longer before reaching SQL. The Mann-Whitney U test (p = {`python} f"{mw_p_val:.4f}" if mw_p_val is not None else "N/A"`) indicates this difference is statistically significant. This is an important distinction---if the leads themselves were lower quality, I would expect the conversion rate gap to appear regardless of timing. The fact that Mx leads *do* convert but take longer to get there suggests the bottleneck is on the sales side (follow-up cadence, enablement materials, product familiarity) rather than the marketing side (lead quality, targeting).

## Recycled Lead Heatmap

```{python}
#| label: recycled-heatmap
#| fig-cap: "Recycled Mx leads by industry and seniority. These are not lost---they are dormant."

df_mx_recycled = df[(df['product_segment'] == 'Mx') & (df['outcome_tier'] == 'Near-Miss')].copy()

pivot = pd.crosstab(df_mx_recycled['acct_target_industry'],
                    df_mx_recycled['title_seniority'],
                    margins=False)

pivot = pivot.loc[pivot.sum(axis=1) >= 5,
                  pivot.sum(axis=0) >= 5]

fig, ax = plt.subplots(figsize=(8, 5))

sns.heatmap(pivot, annot=True, fmt='d', cmap='YlOrRd',
            cbar_kws={'label': 'Count of Recycled Leads'},
            ax=ax, linewidths=0.5)

ax.set_title('Recycled Mx Leads by Industry × Seniority\n(Potential Nurture Targets)',
            fontweight='bold', fontsize=14)
ax.set_xlabel('Title Seniority', fontsize=12)
ax.set_ylabel('Target Industry', fontsize=12)

total = pivot.values.sum()
top_cell = pivot.stack().idxmax()
top_count = pivot.stack().max()
ax.annotate(f"{total} total recycled leads; largest pocket: {top_cell[0]} × {top_cell[1]} = {top_count}",
            xy=(0.5, -0.12), xycoords='axes fraction',
            fontsize=10, fontstyle='italic', color=COL_ACCENT, ha='center')

plt.tight_layout()
plt.savefig(here("output/eda_recycled_heatmap.png"), dpi=300)
plt.show()
```

```{python}
#| label: recycled-summary

recycled_summary = pd.DataFrame({
    'Metric': ['Total Recycled Mx Leads', 'Decision Maker Rate', 'Top Industry', 'Top Seniority'],
    'Value': [
        f"{len(df_mx_recycled):,}",
        f"{df_mx_recycled['is_decision_maker'].mean():.1%}",
        df_mx_recycled['acct_target_industry'].value_counts().index[0]
            if len(df_mx_recycled) > 0 else "N/A",
        df_mx_recycled['title_seniority'].value_counts().index[0]
            if len(df_mx_recycled) > 0 else "N/A"
    ]
})
print_table(recycled_summary, caption="Recycled Mx Lead Summary")
```

The heatmap reveals where the dormant pipeline sits. These recycled leads were not disqualified on quality grounds---they simply stalled. The densest cells indicate which industry-seniority combinations would benefit most from a re-engagement campaign. I think this is the lowest-hanging fruit in the analysis: these contacts already engaged with MasterControl once and may convert with a better-timed or better-positioned follow-up.

---

# Signal Detection

This section moves beyond univariate bar charts to identify which specific title words, seniority-industry combinations, and scope modifiers predict conversion. My goal here was to find actionable targeting signals that go beyond the broad categories I already engineered.

## Semantic Signal Analysis (Log-Odds)

```{python}
#| label: log-odds
#| fig-cap: "Title words and phrases associated with higher (green) or lower (orange) Mx conversion."

def semantic_log_odds(df, product_filter='Mx', ngram_range=(1, 2), min_freq=15):
    """
    Log-odds analysis with bigrams. This captures context that single-word
    parsing misses---for example, "Quality Manager" and "Project Manager"
    have very different conversion profiles.
    """
    subset = df[df['product_segment'] == product_filter].copy()

    vec = CountVectorizer(
        stop_words='english',
        min_df=5,
        ngram_range=ngram_range,
        token_pattern=r'\b[a-zA-Z]{2,}\b'
    )

    X = vec.fit_transform(subset['contact_lead_title'].fillna(''))
    words = np.array(vec.get_feature_names_out())

    y = subset['is_success'].values
    x_pos = np.array(X[y==1].sum(axis=0)).flatten()
    x_neg = np.array(X[y==0].sum(axis=0)).flatten()

    # Log-odds with Laplace smoothing
    p_pos = (x_pos + 1) / (x_pos.sum() + len(words))
    p_neg = (x_neg + 1) / (x_neg.sum() + len(words))

    log_odds = np.log(p_pos / p_neg)

    res = pd.DataFrame({
        'phrase': words,
        'log_odds': log_odds,
        'freq': x_pos + x_neg
    })

    res = res[res['freq'] >= min_freq]

    top_positive = res.nlargest(12, 'log_odds')
    top_negative = res.nsmallest(8, 'log_odds')
    top_signals = pd.concat([top_positive, top_negative]).sort_values('log_odds', ascending=True)

    fig, ax = plt.subplots(figsize=(8, 6))

    colors = [COL_SUCCESS if x > 0 else COL_RISK for x in top_signals['log_odds']]

    y_pos = range(len(top_signals))
    ax.barh(y_pos, top_signals['log_odds'], color=colors, edgecolor='white')

    for i, row in enumerate(top_signals.itertuples()):
        label = f"{row.phrase} (n={row.freq})"
        ax.text(0.01 if row.log_odds > 0 else -0.01, i, label,
               va='center', ha='left' if row.log_odds > 0 else 'right', fontsize=9)

    ax.axvline(0, color='black', linewidth=1)
    ax.set_yticks([])
    ax.set_xlabel('Log-Odds Ratio (Right = Higher Conversion, Left = Lower)', fontsize=11)
    ax.set_title(f'Title Words/Phrases Predicting {product_filter} Conversion',
                fontweight='bold')

    best_phrase = top_positive.iloc[0]['phrase']
    worst_phrase = top_negative.iloc[0]['phrase']
    ax.annotate(f"Strongest positive signal: '{best_phrase}' | Strongest negative: '{worst_phrase}'",
                xy=(0.5, 0.02), xycoords='axes fraction',
                fontsize=10, fontstyle='italic', color=COL_ACCENT, ha='center')

    sns.despine()
    plt.tight_layout()
    plt.savefig(here("output/eda_log_odds.png"), dpi=300)
    plt.show()

    return top_positive, top_negative

top_pos, top_neg = semantic_log_odds(df, 'Mx')
```

```{python}
#| label: log-odds-tables

pos_df = top_pos.head(8)[['phrase', 'log_odds', 'freq']].copy()
pos_df.columns = ['Phrase', 'Log-Odds', 'Frequency']
pos_df['Log-Odds'] = pos_df['Log-Odds'].apply(lambda x: f"{x:.3f}")
pos_df['Frequency'] = pos_df['Frequency'].astype(int)
print_table(pos_df, caption="Top Phrases Predicting Conversion")

neg_df = top_neg.head(5)[['phrase', 'log_odds', 'freq']].copy()
neg_df.columns = ['Phrase', 'Log-Odds', 'Frequency']
neg_df['Log-Odds'] = neg_df['Log-Odds'].apply(lambda x: f"{x:.3f}")
neg_df['Frequency'] = neg_df['Frequency'].astype(int)
print_table(neg_df, caption="Phrases Predicting Non-Conversion")
```

The log-odds analysis goes beyond the seniority/function categories I already engineered and surfaces the specific words and bigrams in contact titles that predict Mx conversion. Positive log-odds (green) indicate phrases appearing more often in converted leads; negative (orange) appear more often in non-converted leads. This serves two purposes: it validates my seniority parsing (director-level terms should appear on the right side of the chart), and it surfaces signals the regex categories may have missed entirely---bigrams like "quality director" vs "project coordinator" carry very different conversion profiles that single-word parsing would flatten.

## Seniority × Industry × Model Interaction

```{python}
#| label: power-trio
#| fig-cap: "Conversion rates by Seniority × Industry × Manufacturing Model for Mx. Green = above average, orange = below."

def analyze_segment_interactions(df, product='Mx', min_n=15):
    """
    Find the highest- and lowest-converting combinations of
    Seniority x Industry x Manufacturing Model.
    """
    df_product = df[df['product_segment'] == product].copy()

    trio_stats = df_product.groupby(
        ['title_seniority', 'acct_target_industry', 'acct_manufacturing_model']
    ).agg(
        n=('is_success', 'size'),
        successes=('is_success', 'sum')
    ).reset_index()

    trio_stats = trio_stats[trio_stats['n'] >= min_n].copy()

    if len(trio_stats) == 0:
        print(f"No segments with n >= {min_n}")
        return None

    trio_stats['rate'] = trio_stats.apply(
        lambda r: bayesian_conversion_rate(r['successes'], r['n'])[0], axis=1)
    trio_stats['ci_low'] = trio_stats.apply(
        lambda r: bayesian_conversion_rate(r['successes'], r['n'])[1], axis=1)
    trio_stats['ci_high'] = trio_stats.apply(
        lambda r: bayesian_conversion_rate(r['successes'], r['n'])[2], axis=1)

    trio_stats['segment'] = (trio_stats['title_seniority'] + ' | ' +
                             trio_stats['acct_target_industry'] + ' | ' +
                             trio_stats['acct_manufacturing_model'])

    trio_stats = trio_stats.sort_values('rate', ascending=False)

    top_segments = pd.concat([trio_stats.head(10), trio_stats.tail(5)])

    fig, ax = plt.subplots(figsize=(8, 6))

    y_pos = range(len(top_segments))
    colors = [COL_SUCCESS if r > df_product['is_success'].mean()
              else COL_RISK for r in top_segments['rate']]

    bars = ax.barh(y_pos, top_segments['rate'], color=colors, edgecolor='white')

    for i, (idx, row) in enumerate(top_segments.iterrows()):
        ax.plot([row['ci_low'], row['ci_high']], [i, i], color='black', linewidth=2)
        ax.text(row['rate'] + 0.01, i, f"{row['rate']:.0%} (n={row['n']})",
                va='center', fontsize=9)

    ax.set_yticks(y_pos)
    ax.set_yticklabels(top_segments['segment'], fontsize=9)
    ax.axvline(x=df_product['is_success'].mean(), color='gray', linestyle='--',
               alpha=0.7, label=f'{product} Average: {df_product["is_success"].mean():.1%}')
    ax.set_xlabel('Conversion Rate', fontsize=11)
    ax.set_title(f'{product} Conversion by Seniority × Industry × Model',
                fontweight='bold')
    ax.legend(loc='lower right')
    ax.set_xlim(0, 0.50)

    best = trio_stats.iloc[0]
    ax.annotate(f"Top segment: '{best['segment']}' at {best['rate']:.0%} "
                f"({best['rate']/df_product['is_success'].mean():.1f}x average)",
                xy=(0.5, 0.02), xycoords='axes fraction',
                fontsize=10, fontstyle='italic', color=COL_ACCENT, ha='center')

    sns.despine()
    plt.tight_layout()
    plt.savefig(here("output/eda_segment_interactions.png"), dpi=300)
    plt.show()

    return trio_stats

segment_stats = analyze_segment_interactions(df, 'Mx')
```

```{python}
#| label: segment-table

if segment_stats is not None:
    seg_df = segment_stats.head(10)[['segment', 'n', 'rate', 'ci_low', 'ci_high']].copy()
    seg_df.columns = ['Segment', 'N', 'Rate', 'CI Low', 'CI High']
    seg_df['Rate']    = seg_df['Rate'].apply(lambda x: f"{x:.1%}")
    seg_df['CI Low']  = seg_df['CI Low'].apply(lambda x: f"{x:.1%}")
    seg_df['CI High'] = seg_df['CI High'].apply(lambda x: f"{x:.1%}")
    print_table(seg_df, caption="Top 10 Mx Segments by Conversion Rate")
```

The three-way interaction reveals the ideal customer profile (ICP) for Mx. Rather than optimizing seniority, industry, or manufacturing model in isolation, this analysis identifies which *combinations* produce outsized conversion rates. I filtered to segments with at least 15 observations to avoid small-sample noise, and used Bayesian credible intervals so the uncertainty is visible. The top-converting segments convert at multiples of the Mx average, which means that targeted outreach to these specific combinations should yield meaningfully better pipeline efficiency than broad-based campaigns.

## Scope Lift Analysis

```{python}
#| label: scope-lift
#| fig-cap: "Conversion rate by title scope for Mx. 'Global' titles convert at a meaningfully higher rate."

df_product_scope = df[df['product_segment'] == 'Mx'].copy()

scope_stats = df_product_scope.groupby('title_scope').agg(
    n=('is_success', 'size'),
    successes=('is_success', 'sum')
).reset_index()

scope_stats['rate'] = scope_stats.apply(
    lambda r: bayesian_conversion_rate(r['successes'], r['n'])[0], axis=1)
scope_stats['ci_low'] = scope_stats.apply(
    lambda r: bayesian_conversion_rate(r['successes'], r['n'])[1], axis=1)
scope_stats['ci_high'] = scope_stats.apply(
    lambda r: bayesian_conversion_rate(r['successes'], r['n'])[2], axis=1)

baseline_rate = scope_stats[scope_stats['title_scope'] == 'Standard']['rate'].values
baseline_rate = baseline_rate[0] if len(baseline_rate) > 0 else df_product_scope['is_success'].mean()
scope_stats['lift'] = scope_stats['rate'] / baseline_rate

scope_stats = scope_stats.sort_values('rate', ascending=True)

fig, ax = plt.subplots(figsize=(8, 5))

y_pos = range(len(scope_stats))
colors = [COL_SUCCESS if r > df_product_scope['is_success'].mean() else COL_RISK
          for r in scope_stats['rate']]

bars = ax.barh(y_pos, scope_stats['rate'], color=colors, edgecolor='white', height=0.6)

for i, (idx, row) in enumerate(scope_stats.iterrows()):
    ax.plot([row['ci_low'], row['ci_high']], [i, i], color='black', linewidth=2)
    lift_str = f" ({row['lift']:.1f}x)" if row['title_scope'] != 'Standard' else " (baseline)"
    ax.text(row['rate'] + 0.01, i, f"{row['rate']:.1%}{lift_str} (n={row['n']})",
           va='center', fontsize=10)

ax.set_yticks(y_pos)
ax.set_yticklabels(scope_stats['title_scope'])
ax.axvline(x=df_product_scope['is_success'].mean(), color='gray', linestyle='--', alpha=0.7,
           label=f'Mx Average: {df_product_scope["is_success"].mean():.1%}')
ax.set_xlabel('Conversion Rate', fontsize=11)
ax.set_title('Impact of Title Scope on Mx Conversion', fontweight='bold')
ax.legend(loc='lower right')
ax.set_xlim(0, 0.35)

global_stats = scope_stats[scope_stats['title_scope'] == 'Global']
if len(global_stats) > 0:
    global_lift = global_stats['lift'].values[0]
    ax.annotate(f"'Global' scope = {global_lift:.1f}x lift over baseline",
                xy=(0.5, 0.02), xycoords='axes fraction',
                fontsize=10, fontstyle='italic', color=COL_ACCENT, ha='center')

sns.despine()
plt.tight_layout()
plt.savefig(here("output/eda_scope_lift.png"), dpi=300)
plt.show()
```

```{python}
#| label: scope-table

scope_df = scope_stats[['title_scope', 'n', 'rate', 'lift']].copy()
scope_df.columns = ['Scope', 'N', 'Rate', 'Lift']
scope_df['Rate'] = scope_df['Rate'].apply(lambda x: f"{x:.1%}")
scope_df['Lift'] = scope_df.apply(
    lambda r: "baseline" if r['Scope'] == 'Standard' else f"{r['Lift']:.1f}x"
    if isinstance(r['Lift'], (int, float)) else r['Lift'], axis=1)
print_table(scope_df, caption="Scope Lift Analysis (Mx)")
```

Scope is a lightweight but effective targeting signal. Contacts with "Global," "Corporate," or "Enterprise" in their titles convert at a meaningfully higher rate than site-level or standard titles. This makes intuitive sense for an enterprise software product like Mx---contacts with broader organizational authority are more likely to have the budget and decision-making power to move a deal forward. I think this is one of the more directly actionable findings for the sales team because it requires no model---just a title filter in the CRM.

---

# Export and Conclusion

```{python}
#| label: export
#| include: false

# =============================================================================
# Export enriched dataset for modeling phase
# =============================================================================

export_cols = [
    'qal_id', 'contact_lead_id',
    'is_success', 'outcome_tier', 'next_stage__c',
    'product_segment', 'solution_rollup',
    'acct_target_industry', 'acct_manufacturing_model',
    'acct_primary_site_function', 'acct_territory_rollup', 'acct_tier_rollup',
    'contact_lead_title', 'title_seniority', 'title_function',
    'title_scope', 'is_decision_maker',
    'record_completeness', 'completeness_tier',
    'priority', 'last_tactic_campaign_channel',
    'cohort_date', 'cohort_year', 'cohort_quarter', 'lead_age_days'
]

export_cols = [c for c in export_cols if c in df.columns]
df_export = df[export_cols].copy()
df_export.to_csv(CLEANED_DATA_PATH, index=False)
```

## Conclusion

This exploratory analysis surfaces four actionable findings for MasterControl's Mx product line:

1. **The gap is real but diagnosable.** Mx converts at approximately 12.7% vs Qx at 19.7%. The 95% Bayesian credible intervals do not overlap, confirming this is not a sampling artifact.

2. **Velocity, not quality, is the primary bottleneck.** Mx leads that *do* convert take roughly 23 additional days to reach SQL compared to Qx. This points to sales process friction---follow-up cadence, enablement materials, or product-specific training---rather than a fundamental targeting problem.

3. **High-value segments exist and are identifiable.** The three-way interaction analysis (Seniority × Industry × Manufacturing Model) reveals specific micro-segments that convert at 2–3x the Mx average. Similarly, contacts with "Global" scope in their titles convert at meaningfully higher rates than site-level contacts. These findings define the ideal customer profile for Mx targeting.

4. **The recycled pipeline is an untapped asset.** Hundreds of Mx leads sit in recycled status---they were not disqualified but simply stalled. The heatmap identifies which industry-seniority combinations contain the densest pockets of these dormant leads, providing a clear starting point for re-engagement campaigns.

These findings and the engineered features (seniority, function, scope, record completeness) feed directly into the team's modeling phase, where they serve as candidate predictors for a lead scoring model.

---

*MasterControl EDA V3 — Thomas Beck, Spring 2026*
